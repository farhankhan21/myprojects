{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Copy of main.ipynb","provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"code","metadata":{"id":"z3QxaSVUcaBZ","colab_type":"code","outputId":"4d3c1e6f-31c8-487a-dc4e-ccad423f74ad","executionInfo":{"status":"ok","timestamp":1574406881761,"user_tz":-300,"elapsed":32789,"user":{"displayName":"Farhan Khan","photoUrl":"","userId":"10856133339110987941"}},"colab":{"base_uri":"https://localhost:8080/","height":128}},"source":["from google.colab import drive\n","drive.mount('/content/drive')\n"],"execution_count":1,"outputs":[{"output_type":"stream","text":["Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n","\n","Enter your authorization code:\n","··········\n","Mounted at /content/drive\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"jOvJhGjWpiSd","colab_type":"code","outputId":"ed666457-60d1-4e54-8acc-366f86864572","executionInfo":{"status":"ok","timestamp":1574406886457,"user_tz":-300,"elapsed":2045,"user":{"displayName":"Farhan Khan","photoUrl":"","userId":"10856133339110987941"}},"colab":{"base_uri":"https://localhost:8080/","height":35}},"source":["cd /content/drive/My Drive/Colab Notebooks/vpt/"],"execution_count":2,"outputs":[{"output_type":"stream","text":["/content/drive/My Drive/Colab Notebooks/vpt\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"ndumJ29PxDtp","colab_type":"code","outputId":"6a6f8d45-3147-45f7-bd75-fe1667377e5e","executionInfo":{"status":"ok","timestamp":1574406992747,"user_tz":-300,"elapsed":102656,"user":{"displayName":"Farhan Khan","photoUrl":"","userId":"10856133339110987941"}},"colab":{"base_uri":"https://localhost:8080/","height":1000}},"source":["!pip install -r requirements.txt"],"execution_count":3,"outputs":[{"output_type":"stream","text":["Collecting tensorlayer>=2.0.0\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/66/7d/80daea9f4359253b76266bc3d4ebd665b5a56eab4117a96d60e63f2182cb/tensorlayer-2.1.0-py2.py3-none-any.whl (353kB)\n","\u001b[K     |████████████████████████████████| 358kB 4.9MB/s \n","\u001b[?25hCollecting tensorflow>=2.0.0b1\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/46/0f/7bd55361168bb32796b360ad15a25de6966c9c1beb58a8e30c01c8279862/tensorflow-2.0.0-cp36-cp36m-manylinux2010_x86_64.whl (86.3MB)\n","\u001b[K     |████████████████████████████████| 86.3MB 26kB/s \n","\u001b[?25hCollecting numpy==1.16.1\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/f5/bf/4981bcbee43934f0adb8f764a1e70ab0ee5a448f6505bd04a87a2fda2a8b/numpy-1.16.1-cp36-cp36m-manylinux1_x86_64.whl (17.3MB)\n","\u001b[K     |████████████████████████████████| 17.3MB 140kB/s \n","\u001b[?25hRequirement already satisfied: easydict==1.9 in /usr/local/lib/python3.6/dist-packages (from -r requirements.txt (line 4)) (1.9)\n","Requirement already satisfied: requests==2.21.0 in /usr/local/lib/python3.6/dist-packages (from tensorlayer>=2.0.0->-r requirements.txt (line 1)) (2.21.0)\n","Collecting imageio==2.5.0\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/af/0a/943c965d372dae0b1f1482677d29030ab834351a61a9a632fd62f27f1523/imageio-2.5.0-py3-none-any.whl (3.3MB)\n","\u001b[K     |████████████████████████████████| 3.3MB 43.5MB/s \n","\u001b[?25hCollecting progressbar2==3.39.3\n","  Downloading https://files.pythonhosted.org/packages/fb/89/d90f9ff03285d8eb56994e8cec1b73a4d0dc9bb529c1f8e8e10b1b663843/progressbar2-3.39.3-py2.py3-none-any.whl\n","Collecting wrapt==1.11.1\n","  Downloading https://files.pythonhosted.org/packages/67/b2/0f71ca90b0ade7fad27e3d20327c996c6252a2ffe88f50a95bba7434eda9/wrapt-1.11.1.tar.gz\n","Collecting scikit-learn==0.21.0\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/b7/6c/ec121123c671d980c6969dfc69d0f09e1d7f88d80d373f511e61d773b85c/scikit_learn-0.21.0-cp36-cp36m-manylinux1_x86_64.whl (6.6MB)\n","\u001b[K     |████████████████████████████████| 6.6MB 37.2MB/s \n","\u001b[?25hCollecting h5py>=2.9\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/60/06/cafdd44889200e5438b897388f3075b52a8ef01f28a17366d91de0fa2d05/h5py-2.10.0-cp36-cp36m-manylinux1_x86_64.whl (2.9MB)\n","\u001b[K     |████████████████████████████████| 2.9MB 39.8MB/s \n","\u001b[?25hRequirement already satisfied: cloudpickle>=0.8.1 in /usr/local/lib/python3.6/dist-packages (from tensorlayer>=2.0.0->-r requirements.txt (line 1)) (1.2.2)\n","Requirement already satisfied: scikit-image==0.15.0 in /usr/local/lib/python3.6/dist-packages (from tensorlayer>=2.0.0->-r requirements.txt (line 1)) (0.15.0)\n","Collecting scipy==1.2.1\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/7f/5f/c48860704092933bf1c4c1574a8de1ffd16bf4fde8bab190d747598844b2/scipy-1.2.1-cp36-cp36m-manylinux1_x86_64.whl (24.8MB)\n","\u001b[K     |████████████████████████████████| 24.8MB 79kB/s \n","\u001b[?25hRequirement already satisfied: gast==0.2.2 in /usr/local/lib/python3.6/dist-packages (from tensorflow>=2.0.0b1->-r requirements.txt (line 2)) (0.2.2)\n","Collecting tensorflow-estimator<2.1.0,>=2.0.0\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/fc/08/8b927337b7019c374719145d1dceba21a8bb909b93b1ad6f8fb7d22c1ca1/tensorflow_estimator-2.0.1-py2.py3-none-any.whl (449kB)\n","\u001b[K     |████████████████████████████████| 450kB 47.7MB/s \n","\u001b[?25hRequirement already satisfied: google-pasta>=0.1.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow>=2.0.0b1->-r requirements.txt (line 2)) (0.1.8)\n","Requirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow>=2.0.0b1->-r requirements.txt (line 2)) (1.15.0)\n","Requirement already satisfied: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.6/dist-packages (from tensorflow>=2.0.0b1->-r requirements.txt (line 2)) (1.1.0)\n","Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.6/dist-packages (from tensorflow>=2.0.0b1->-r requirements.txt (line 2)) (3.1.0)\n","Requirement already satisfied: absl-py>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow>=2.0.0b1->-r requirements.txt (line 2)) (0.8.1)\n","Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.6/dist-packages (from tensorflow>=2.0.0b1->-r requirements.txt (line 2)) (0.33.6)\n","Requirement already satisfied: protobuf>=3.6.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow>=2.0.0b1->-r requirements.txt (line 2)) (3.10.0)\n","Requirement already satisfied: keras-applications>=1.0.8 in /usr/local/lib/python3.6/dist-packages (from tensorflow>=2.0.0b1->-r requirements.txt (line 2)) (1.0.8)\n","Requirement already satisfied: astor>=0.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow>=2.0.0b1->-r requirements.txt (line 2)) (0.8.0)\n","Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow>=2.0.0b1->-r requirements.txt (line 2)) (1.12.0)\n","Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow>=2.0.0b1->-r requirements.txt (line 2)) (1.1.0)\n","Collecting tensorboard<2.1.0,>=2.0.0\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d3/9e/a48cd34dd7b672ffc227b566f7d16d63c62c58b542d54efa45848c395dd4/tensorboard-2.0.1-py3-none-any.whl (3.8MB)\n","\u001b[K     |████████████████████████████████| 3.8MB 44.5MB/s \n","\u001b[?25hRequirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests==2.21.0->tensorlayer>=2.0.0->-r requirements.txt (line 1)) (3.0.4)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests==2.21.0->tensorlayer>=2.0.0->-r requirements.txt (line 1)) (2019.9.11)\n","Requirement already satisfied: idna<2.9,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests==2.21.0->tensorlayer>=2.0.0->-r requirements.txt (line 1)) (2.8)\n","Requirement already satisfied: urllib3<1.25,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests==2.21.0->tensorlayer>=2.0.0->-r requirements.txt (line 1)) (1.24.3)\n","Requirement already satisfied: pillow in /usr/local/lib/python3.6/dist-packages (from imageio==2.5.0->tensorlayer>=2.0.0->-r requirements.txt (line 1)) (4.3.0)\n","Requirement already satisfied: python-utils>=2.3.0 in /usr/local/lib/python3.6/dist-packages (from progressbar2==3.39.3->tensorlayer>=2.0.0->-r requirements.txt (line 1)) (2.3.0)\n","Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.6/dist-packages (from scikit-learn==0.21.0->tensorlayer>=2.0.0->-r requirements.txt (line 1)) (0.14.0)\n","Requirement already satisfied: networkx>=2.0 in /usr/local/lib/python3.6/dist-packages (from scikit-image==0.15.0->tensorlayer>=2.0.0->-r requirements.txt (line 1)) (2.4)\n","Requirement already satisfied: PyWavelets>=0.4.0 in /usr/local/lib/python3.6/dist-packages (from scikit-image==0.15.0->tensorlayer>=2.0.0->-r requirements.txt (line 1)) (1.1.1)\n","Requirement already satisfied: matplotlib!=3.0.0,>=2.0.0 in /usr/local/lib/python3.6/dist-packages (from scikit-image==0.15.0->tensorlayer>=2.0.0->-r requirements.txt (line 1)) (3.1.1)\n","Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from protobuf>=3.6.1->tensorflow>=2.0.0b1->-r requirements.txt (line 2)) (41.6.0)\n","Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.1.0,>=2.0.0->tensorflow>=2.0.0b1->-r requirements.txt (line 2)) (0.16.0)\n","Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.1.0,>=2.0.0->tensorflow>=2.0.0b1->-r requirements.txt (line 2)) (3.1.1)\n","Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.1.0,>=2.0.0->tensorflow>=2.0.0b1->-r requirements.txt (line 2)) (0.4.1)\n","Collecting google-auth<2,>=1.6.3\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/7b/cb/786dc53d93494784935a62947643b48250b84a882474e714f9af5e1a1928/google_auth-1.7.1-py2.py3-none-any.whl (74kB)\n","\u001b[K     |████████████████████████████████| 81kB 10.7MB/s \n","\u001b[?25hRequirement already satisfied: olefile in /usr/local/lib/python3.6/dist-packages (from pillow->imageio==2.5.0->tensorlayer>=2.0.0->-r requirements.txt (line 1)) (0.46)\n","Requirement already satisfied: decorator>=4.3.0 in /usr/local/lib/python3.6/dist-packages (from networkx>=2.0->scikit-image==0.15.0->tensorlayer>=2.0.0->-r requirements.txt (line 1)) (4.4.1)\n","Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.6/dist-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image==0.15.0->tensorlayer>=2.0.0->-r requirements.txt (line 1)) (0.10.0)\n","Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image==0.15.0->tensorlayer>=2.0.0->-r requirements.txt (line 1)) (1.1.0)\n","Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image==0.15.0->tensorlayer>=2.0.0->-r requirements.txt (line 1)) (2.6.1)\n","Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image==0.15.0->tensorlayer>=2.0.0->-r requirements.txt (line 1)) (2.4.5)\n","Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.1.0,>=2.0.0->tensorflow>=2.0.0b1->-r requirements.txt (line 2)) (1.3.0)\n","Requirement already satisfied: rsa<4.1,>=3.1.4 in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard<2.1.0,>=2.0.0->tensorflow>=2.0.0b1->-r requirements.txt (line 2)) (4.0)\n","Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard<2.1.0,>=2.0.0->tensorflow>=2.0.0b1->-r requirements.txt (line 2)) (0.2.7)\n","Requirement already satisfied: cachetools<3.2,>=2.0.0 in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard<2.1.0,>=2.0.0->tensorflow>=2.0.0b1->-r requirements.txt (line 2)) (3.1.1)\n","Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.6/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.1.0,>=2.0.0->tensorflow>=2.0.0b1->-r requirements.txt (line 2)) (3.1.0)\n","Requirement already satisfied: pyasn1>=0.1.3 in /usr/local/lib/python3.6/dist-packages (from rsa<4.1,>=3.1.4->google-auth<2,>=1.6.3->tensorboard<2.1.0,>=2.0.0->tensorflow>=2.0.0b1->-r requirements.txt (line 2)) (0.4.7)\n","Building wheels for collected packages: wrapt\n","  Building wheel for wrapt (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for wrapt: filename=wrapt-1.11.1-cp36-cp36m-linux_x86_64.whl size=67443 sha256=b2927ab8183beeab752b77f7332299ed77a2cbef0c9a61e35879aa6641edb62e\n","  Stored in directory: /root/.cache/pip/wheels/89/67/41/63cbf0f6ac0a6156588b9587be4db5565f8c6d8ccef98202fc\n","Successfully built wrapt\n","\u001b[31mERROR: tensorboard 2.0.1 has requirement grpcio>=1.24.3, but you'll have grpcio 1.15.0 which is incompatible.\u001b[0m\n","\u001b[31mERROR: google-colab 1.0.0 has requirement google-auth~=1.4.0, but you'll have google-auth 1.7.1 which is incompatible.\u001b[0m\n","\u001b[31mERROR: datascience 0.10.6 has requirement folium==0.2.1, but you'll have folium 0.8.3 which is incompatible.\u001b[0m\n","\u001b[31mERROR: albumentations 0.1.12 has requirement imgaug<0.2.7,>=0.2.5, but you'll have imgaug 0.2.9 which is incompatible.\u001b[0m\n","Installing collected packages: numpy, imageio, progressbar2, wrapt, scipy, scikit-learn, h5py, tensorlayer, tensorflow-estimator, google-auth, tensorboard, tensorflow\n","  Found existing installation: numpy 1.17.4\n","    Uninstalling numpy-1.17.4:\n","      Successfully uninstalled numpy-1.17.4\n","  Found existing installation: imageio 2.4.1\n","    Uninstalling imageio-2.4.1:\n","      Successfully uninstalled imageio-2.4.1\n","  Found existing installation: progressbar2 3.38.0\n","    Uninstalling progressbar2-3.38.0:\n","      Successfully uninstalled progressbar2-3.38.0\n","  Found existing installation: wrapt 1.11.2\n","    Uninstalling wrapt-1.11.2:\n","      Successfully uninstalled wrapt-1.11.2\n","  Found existing installation: scipy 1.3.2\n","    Uninstalling scipy-1.3.2:\n","      Successfully uninstalled scipy-1.3.2\n","  Found existing installation: scikit-learn 0.21.3\n","    Uninstalling scikit-learn-0.21.3:\n","      Successfully uninstalled scikit-learn-0.21.3\n","  Found existing installation: h5py 2.8.0\n","    Uninstalling h5py-2.8.0:\n","      Successfully uninstalled h5py-2.8.0\n","  Found existing installation: tensorflow-estimator 1.15.1\n","    Uninstalling tensorflow-estimator-1.15.1:\n","      Successfully uninstalled tensorflow-estimator-1.15.1\n","  Found existing installation: google-auth 1.4.2\n","    Uninstalling google-auth-1.4.2:\n","      Successfully uninstalled google-auth-1.4.2\n","  Found existing installation: tensorboard 1.15.0\n","    Uninstalling tensorboard-1.15.0:\n","      Successfully uninstalled tensorboard-1.15.0\n","  Found existing installation: tensorflow 1.15.0\n","    Uninstalling tensorflow-1.15.0:\n","      Successfully uninstalled tensorflow-1.15.0\n","Successfully installed google-auth-1.7.1 h5py-2.10.0 imageio-2.5.0 numpy-1.16.1 progressbar2-3.39.3 scikit-learn-0.21.0 scipy-1.2.1 tensorboard-2.0.1 tensorflow-2.0.0 tensorflow-estimator-2.0.1 tensorlayer-2.1.0 wrapt-1.11.1\n"],"name":"stdout"},{"output_type":"display_data","data":{"application/vnd.colab-display-data+json":{"pip_warning":{"packages":["google","numpy"]}}},"metadata":{"tags":[]}}]},{"cell_type":"code","metadata":{"id":"x1bmxjBvnYVQ","colab_type":"code","colab":{}},"source":["import os\n","import time\n","import random\n","import numpy as np\n","import scipy, multiprocessing\n","import tensorflow as tf\n","import tensorlayer as tl\n","from tensorlayer.layers import (Input, Conv2d, BatchNorm2d, Elementwise, SubpixelConv2d, Flatten, Dense)\n","from tensorlayer.models import Model"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"q1QDa9g4kEFB","colab_type":"code","colab":{}},"source":["from easydict import EasyDict as edict\n","import json\n","\n","config = edict()\n","config.TRAIN = edict()\n","\n","## Adam\n","config.TRAIN.batch_size = 2 # [16] use 8 if your GPU memory is small, and use [2, 4] in tl.vis.save_images / use 16 for faster training\n","config.TRAIN.lr_init = 1e-4\n","config.TRAIN.beta1 = 0.9\n","\n","## initialize G\n","config.TRAIN.n_epoch_init = 2\n","\n","## adversarial learning (SRGAN)\n","config.TRAIN.n_epoch = 2\n","config.TRAIN.lr_decay = 0.1\n","config.TRAIN.decay_every = int(config.TRAIN.n_epoch / 2)\n","\n","## train set location\n","config.TRAIN.hr_img_path = '/content/drive/My Drive/Colab Notebooks/vpt/celeb_HR/'\n","config.TRAIN.lr_img_path = '/content/drive/My Drive/Colab Notebooks/vpt/celeb_HR/'\n","#train_hr_imgs = tl.files.load_flickr25k_dataset(tag=None)\n","config.VALID = edict()\n","## test set location\n","config.VALID.hr_img_path = '/content/drive/My Drive/Colab Notebooks/vpt/celeb_LR/'\n","config.VALID.lr_img_path = '/content/drive/My Drive/Colab Notebooks/vpt/celeb_LR/'\n","\n","def log_config(filename, cfg):\n","    with open(filename, 'w') as f:\n","        f.write(\"================================================\\n\")\n","        f.write(json.dumps(cfg, indent=4))\n","        f.write(\"\\n================================================\\n\")\n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"wlp38yK2dNBk","colab_type":"code","colab":{}},"source":["\n","\n","def get_G(input_shape):\n","    w_init = tf.random_normal_initializer(stddev=0.02)\n","    g_init = tf.random_normal_initializer(1., 0.02)\n","\n","    nin = Input(input_shape)\n","    n = Conv2d(64, (3, 3), (1, 1), act=tf.nn.relu, padding='SAME', W_init=w_init)(nin)\n","    temp = n\n","\n","    # B residual blocks\n","    for i in range(16):\n","        nn = Conv2d(64, (3, 3), (1, 1), padding='SAME', W_init=w_init, b_init=None)(n)\n","        nn = BatchNorm2d(act=tf.nn.relu, gamma_init=g_init)(nn)\n","        nn = Conv2d(64, (3, 3), (1, 1), padding='SAME', W_init=w_init, b_init=None)(nn)\n","        nn = BatchNorm2d(gamma_init=g_init)(nn)\n","        nn = Elementwise(tf.add)([n, nn])\n","        n = nn\n","\n","    n = Conv2d(64, (3, 3), (1, 1), padding='SAME', W_init=w_init, b_init=None)(n)\n","    n = BatchNorm2d(gamma_init=g_init)(n)\n","    n = Elementwise(tf.add)([n, temp])\n","    # B residual blacks end\n","\n","    n = Conv2d(256, (3, 3), (1, 1), padding='SAME', W_init=w_init)(n)\n","    n = SubpixelConv2d(scale=2, n_out_channels=None, act=tf.nn.relu)(n)\n","\n","    n = Conv2d(256, (3, 3), (1, 1), act=None, padding='SAME', W_init=w_init)(n)\n","    n = SubpixelConv2d(scale=2, n_out_channels=None, act=tf.nn.relu)(n)\n","\n","    nn = Conv2d(3, (1, 1), (1, 1), act=tf.nn.tanh, padding='SAME', W_init=w_init)(n)\n","    G = Model(inputs=nin, outputs=nn)\n","    print(nn.shape)\n","    return G\n","\n","def get_D(input_shape):\n","    w_init = tf.random_normal_initializer(stddev=0.02)\n","    gamma_init = tf.random_normal_initializer(1., 0.02)\n","    df_dim = 64\n","    lrelu = lambda x: tl.act.lrelu(x, 0.2)\n","\n","    nin = Input(input_shape)\n","    n = Conv2d(df_dim, (4, 4), (2, 2), act=lrelu, padding='SAME', W_init=w_init)(nin)\n","\n","    n = Conv2d(df_dim * 2, (4, 4), (2, 2), padding='SAME', W_init=w_init, b_init=None)(n)\n","    n = BatchNorm2d(act=lrelu, gamma_init=gamma_init)(n)\n","    n = Conv2d(df_dim * 4, (4, 4), (2, 2), padding='SAME', W_init=w_init, b_init=None)(n)\n","    n = BatchNorm2d(act=lrelu, gamma_init=gamma_init)(n)\n","    n = Conv2d(df_dim * 8, (4, 4), (2, 2), padding='SAME', W_init=w_init, b_init=None)(n)\n","    n = BatchNorm2d(act=lrelu, gamma_init=gamma_init)(n)\n","    n = Conv2d(df_dim * 16, (4, 4), (2, 2), padding='SAME', W_init=w_init, b_init=None)(n)\n","    n = BatchNorm2d(act=lrelu, gamma_init=gamma_init)(n)\n","    n = Conv2d(df_dim * 32, (4, 4), (2, 2), padding='SAME', W_init=w_init, b_init=None)(n)\n","    n = BatchNorm2d(act=lrelu, gamma_init=gamma_init)(n)\n","    n = Conv2d(df_dim * 16, (1, 1), (1, 1), padding='SAME', W_init=w_init, b_init=None)(n)\n","    n = BatchNorm2d(act=lrelu, gamma_init=gamma_init)(n)\n","    n = Conv2d(df_dim * 8, (1, 1), (1, 1), padding='SAME', W_init=w_init, b_init=None)(n)\n","    nn = BatchNorm2d(gamma_init=gamma_init)(n)\n","\n","    n = Conv2d(df_dim * 2, (1, 1), (1, 1), padding='SAME', W_init=w_init, b_init=None)(nn)\n","    n = BatchNorm2d(act=lrelu, gamma_init=gamma_init)(n)\n","    n = Conv2d(df_dim * 2, (3, 3), (1, 1), padding='SAME', W_init=w_init, b_init=None)(n)\n","    n = BatchNorm2d(act=lrelu, gamma_init=gamma_init)(n)\n","    n = Conv2d(df_dim * 8, (3, 3), (1, 1), padding='SAME', W_init=w_init, b_init=None)(n)\n","    n = BatchNorm2d(gamma_init=gamma_init)(n)\n","    n = Elementwise(combine_fn=tf.add, act=lrelu)([n, nn])\n","\n","    n = Flatten()(n)\n","    no = Dense(n_units=1, W_init=w_init)(n)\n","    D = Model(inputs=nin, outputs=no)\n","    return D\n","\n","\n","def Vgg19_simple_api(rgb, reuse):\n","#     \"\"\"\n","#     Build the VGG 19 Model\n","#\n","#     Parameters\n","#     -----------\n","#     rgb : rgb image placeholder [batch, height, width, 3] values scaled [0, 1]\n","#     \"\"\"\n","     VGG_MEAN = [103.939, 116.779, 123.68]\n","     with tf.variable_scope(\"VGG19\", reuse=reuse) as vs:\n","         start_time = time.time()\n","         print(\"build model started\")\n","         rgb_scaled = rgb * 255.0\n","         # Convert RGB to BGR\n","         if tf.__version__ <= '0.11':\n","             red, green, blue = tf.split(3, 3, rgb_scaled)\n","         else:  # TF 1.0\n","             # print(rgb_scaled)\n","             red, green, blue = tf.split(rgb_scaled, 3, 3)\n","         assert red.get_shape().as_list()[1:] == [224, 224, 1]\n","         assert green.get_shape().as_list()[1:] == [224, 224, 1]\n","         assert blue.get_shape().as_list()[1:] == [224, 224, 1]\n","         if tf.__version__ <= '0.11':\n","             bgr = tf.concat(3, [\n","                 blue - VGG_MEAN[0],\n","                 green - VGG_MEAN[1],\n","                 red - VGG_MEAN[2],\n","             ])\n","         else:\n","             bgr = tf.concat(\n","                 [\n","                     blue - VGG_MEAN[0],\n","                     green - VGG_MEAN[1],\n","                     red - VGG_MEAN[2],\n","                 ], axis=3)\n","         assert bgr.get_shape().as_list()[1:] == [224, 224, 3]\n","#         \"\"\" input layer \"\"\"\n","         net_in = InputLayer(bgr, name='input')\n","#         \"\"\" conv1 \"\"\"\n","         network = Conv2d(net_in, n_filter=64, filter_size=(3, 3), strides=(1, 1), act=tf.nn.relu, padding='SAME', name='conv1_1')\n","         network = Conv2d(network, n_filter=64, filter_size=(3, 3), strides=(1, 1), act=tf.nn.relu, padding='SAME', name='conv1_2')\n","         network = MaxPool2d(network, filter_size=(2, 2), strides=(2, 2), padding='SAME', name='pool1')\n","#         \"\"\" conv2 \"\"\"\n","         network = Conv2d(network, n_filter=128, filter_size=(3, 3), strides=(1, 1), act=tf.nn.relu, padding='SAME', name='conv2_1')\n","         network = Conv2d(network, n_filter=128, filter_size=(3, 3), strides=(1, 1), act=tf.nn.relu, padding='SAME', name='conv2_2')\n","         network = MaxPool2d(network, filter_size=(2, 2), strides=(2, 2), padding='SAME', name='pool2')\n","#         \"\"\" conv3 \"\"\"\n","         network = Conv2d(network, n_filter=256, filter_size=(3, 3), strides=(1, 1), act=tf.nn.relu, padding='SAME', name='conv3_1')\n","         network = Conv2d(network, n_filter=256, filter_size=(3, 3), strides=(1, 1), act=tf.nn.relu, padding='SAME', name='conv3_2')\n","         network = Conv2d(network, n_filter=256, filter_size=(3, 3), strides=(1, 1), act=tf.nn.relu, padding='SAME', name='conv3_3')\n","         network = Conv2d(network, n_filter=256, filter_size=(3, 3), strides=(1, 1), act=tf.nn.relu, padding='SAME', name='conv3_4')\n","         network = MaxPool2d(network, filter_size=(2, 2), strides=(2, 2), padding='SAME', name='pool3')\n","#         \"\"\" conv4 \"\"\"\n","         network = Conv2d(network, n_filter=512, filter_size=(3, 3), strides=(1, 1), act=tf.nn.relu, padding='SAME', name='conv4_1')\n","         network = Conv2d(network, n_filter=512, filter_size=(3, 3), strides=(1, 1), act=tf.nn.relu, padding='SAME', name='conv4_2')\n","         network = Conv2d(network, n_filter=512, filter_size=(3, 3), strides=(1, 1), act=tf.nn.relu, padding='SAME', name='conv4_3')\n","         network = Conv2d(network, n_filter=512, filter_size=(3, 3), strides=(1, 1), act=tf.nn.relu, padding='SAME', name='conv4_4')\n","         network = MaxPool2d(network, filter_size=(2, 2), strides=(2, 2), padding='SAME', name='pool4')  # (batch_size, 14, 14, 512)\n","         conv = network\n","#         \"\"\" conv5 \"\"\"\n","         network = Conv2d(network, n_filter=512, filter_size=(3, 3), strides=(1, 1), act=tf.nn.relu, padding='SAME', name='conv5_1')\n","         network = Conv2d(network, n_filter=512, filter_size=(3, 3), strides=(1, 1), act=tf.nn.relu, padding='SAME', name='conv5_2')\n","         network = Conv2d(network, n_filter=512, filter_size=(3, 3), strides=(1, 1), act=tf.nn.relu, padding='SAME', name='conv5_3')\n","         network = Conv2d(network, n_filter=512, filter_size=(3, 3), strides=(1, 1), act=tf.nn.relu, padding='SAME', name='conv5_4')\n","         network = MaxPool2d(network, filter_size=(2, 2), strides=(2, 2), padding='SAME', name='pool5')  # (batch_size, 7, 7, 512)\n","#         \"\"\" fc 6~8 \"\"\"\n","         network = FlattenLayer(network, name='flatten')\n","         network = DenseLayer(network, n_units=4096, act=tf.nn.relu, name='fc6')\n","         network = DenseLayer(network, n_units=4096, act=tf.nn.relu, name='fc7')\n","         network = DenseLayer(network, n_units=1000, act=tf.identity, name='fc8')\n","         print(\"build model finished: %fs\" % (time.time() - start_time))\n","         return network, conv\n","\n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"-dw9Qr0_4pRV","colab_type":"code","outputId":"ebf7eeaf-118b-4ba6-c219-d0067207e0af","executionInfo":{"status":"ok","timestamp":1574409126217,"user_tz":-300,"elapsed":2041254,"user":{"displayName":"Farhan Khan","photoUrl":"","userId":"10856133339110987941"}},"colab":{"base_uri":"https://localhost:8080/","height":1000}},"source":["\n","###====================== HYPER-PARAMETERS ===========================###\n","## Adam\n","batch_size = config.TRAIN.batch_size  # use 8 if your GPU memory is small, and change [4, 4] in tl.vis.save_images to [2, 4]\n","lr_init = config.TRAIN.lr_init\n","beta1 = config.TRAIN.beta1\n","## initialize G\n","n_epoch_init = config.TRAIN.n_epoch_init\n","## adversarial learning (SRGAN)\n","n_epoch = config.TRAIN.n_epoch\n","lr_decay = config.TRAIN.lr_decay\n","decay_every = config.TRAIN.decay_every\n","shuffle_buffer_size = 64\n","\n","# ni = int(np.sqrt(batch_size))\n","\n","# create folders to save result images and trained models\n","save_dir = \"/content/drive/My Drive/Colab Notebooks/vpt/celeb_samples/samples\"\n","tl.files.exists_or_mkdir(save_dir)\n","checkpoint_dir = \"/content/drive/My Drive/Colab Notebooks/vpt/celeb_samples/models\"\n","tl.files.exists_or_mkdir(checkpoint_dir)\n","\n","def get_train_data():\n","    # load dataset\n","    train_hr_img_list = sorted(tl.files.load_file_list(path=config.TRAIN.hr_img_path, regx='.*.jpg', printable=False))#[0:20]\n","        # train_lr_img_list = sorted(tl.files.load_file_list(path=config.TRAIN.lr_img_path, regx='.*.png', printable=False))\n","        # valid_hr_img_list = sorted(tl.files.load_file_list(path=config.VALID.hr_img_path, regx='.*.png', printable=False))\n","        # valid_lr_img_list = sorted(tl.files.load_file_list(path=config.VALID.lr_img_path, regx='.*.png', printable=False))\n","\n","    ## If your machine have enough memory, please pre-load the entire train set.\n","    train_hr_imgs = tl.vis.read_images(train_hr_img_list, path=config.TRAIN.hr_img_path, n_threads=32)\n","        # for im in train_hr_imgs:\n","        #     print(im.shape)\n","        # valid_lr_imgs = tl.vis.read_images(valid_lr_img_list, path=config.VALID.lr_img_path, n_threads=32)\n","        # for im in valid_lr_imgs:\n","        #     print(im.shape)\n","        # valid_hr_imgs = tl.vis.read_images(valid_hr_img_list, path=config.VALID.hr_img_path, n_threads=32)\n","        # for im in valid_hr_imgs:\n","        #     print(im.shape)\n","        \n","    # dataset API and augmentation\n","    def generator_train():\n","        for img in train_hr_imgs:\n","            yield img\n","    def _map_fn_train(img):\n","        hr_patch = tf.image.random_crop(img, [128, 128, 3])\n","        hr_patch = hr_patch / (255. / 2.)\n","        hr_patch = hr_patch - 1.\n","        hr_patch = tf.image.random_flip_left_right(hr_patch)\n","        lr_patch = tf.image.resize(hr_patch, size=[32, 32])\n","        #print(hr_patch.shape)\n","        #print(lr_patch.shape)\n","        return lr_patch, hr_patch\n","    train_ds = tf.data.Dataset.from_generator(generator_train, output_types=(tf.float32))\n","    train_ds = train_ds.map(_map_fn_train, num_parallel_calls=multiprocessing.cpu_count())\n","        # train_ds = train_ds.repeat(n_epoch_init + n_epoch)\n","    train_ds = train_ds.shuffle(shuffle_buffer_size)\n","    train_ds = train_ds.prefetch(buffer_size=2)\n","    train_ds = train_ds.batch(batch_size)\n","        # value = train_ds.make_one_shot_iterator().get_next()\n","    return train_ds\n","\n","def train():\n","    G = get_G((batch_size, 64, 64, 3))\n","    D = get_D((batch_size, 128, 128, 3))\n","    VGG = tl.models.vgg19(pretrained=True, end_with='pool4', mode='static')\n","    lr_v = tf.Variable(lr_init)\n","    g_optimizer_init = tf.optimizers.Adam(lr_v, beta_1=beta1)\n","    g_optimizer = tf.optimizers.Adam(lr_v, beta_1=beta1)\n","    d_optimizer = tf.optimizers.Adam(lr_v, beta_1=beta1)\n","\n","    G.train()\n","    D.train()\n","    VGG.train()\n","\n","    train_ds = get_train_data()\n","\n","    ## initialize learning (G)\n","    n_step_epoch = round(n_epoch_init // batch_size)\n","    for epoch in range(n_epoch_init):\n","        for step, (lr_patchs, hr_patchs) in enumerate(train_ds):\n","            if lr_patchs.shape[0] != batch_size: # if the remaining data in this epoch < batch_size\n","                break\n","            step_time = time.time()\n","            with tf.GradientTape() as tape:\n","                fake_hr_patchs = G(lr_patchs)\n","                print(fake_hr_patchs.shape)\n","                print(hr_patchs.shape)\n","                mse_loss = tl.cost.mean_squared_error(fake_hr_patchs, hr_patchs, is_mean=True)\n","            grad = tape.gradient(mse_loss, G.trainable_weights)\n","            g_optimizer_init.apply_gradients(zip(grad, G.trainable_weights))\n","            print(\"Epoch: [{}/{}] step: [{}/{}] time: {:.3f}s, mse: {:.3f} \".format(\n","                epoch, n_epoch_init, step, n_step_epoch, time.time() - step_time, mse_loss))\n","        #if (epoch != 0) and (epoch % 10 == 0):\n","        #    tl.vis.save_images(fake_hr_patchs.numpy(), [2, 4], os.path.join(save_dir, 'train_g_init_{}.png'.format(epoch)))\n","\n","    ## adversarial learning (G, D)\n","    n_step_epoch = round(n_epoch // batch_size)\n","    for epoch in range(n_epoch):\n","        for step, (lr_patchs, hr_patchs) in enumerate(train_ds):\n","            if lr_patchs.shape[0] != batch_size: # if the remaining data in this epoch < batch_size\n","                break\n","            step_time = time.time()\n","            with tf.GradientTape(persistent=True) as tape:\n","                fake_patchs = G(lr_patchs)\n","                logits_fake = D(fake_patchs)\n","                logits_real = D(hr_patchs)\n","                feature_fake = VGG((fake_patchs+1)/2.) # the pre-trained VGG uses the input range of [0, 1]\n","                feature_real = VGG((hr_patchs+1)/2.)\n","                d_loss1 = tl.cost.sigmoid_cross_entropy(logits_real, tf.ones_like(logits_real))\n","                d_loss2 = tl.cost.sigmoid_cross_entropy(logits_fake, tf.zeros_like(logits_fake))\n","                d_loss = d_loss1 + d_loss2\n","                g_gan_loss = 1e-3 * tl.cost.sigmoid_cross_entropy(logits_fake, tf.ones_like(logits_fake))\n","                mse_loss = tl.cost.mean_squared_error(fake_patchs, hr_patchs, is_mean=True)\n","                vgg_loss = 2e-6 * tl.cost.mean_squared_error(feature_fake, feature_real, is_mean=True)\n","                g_loss = mse_loss + vgg_loss + g_gan_loss\n","            grad = tape.gradient(g_loss, G.trainable_weights)\n","            g_optimizer.apply_gradients(zip(grad, G.trainable_weights))\n","            grad = tape.gradient(d_loss, D.trainable_weights)\n","            d_optimizer.apply_gradients(zip(grad, D.trainable_weights))\n","            print(\"Epoch: [{}/{}] step: [{}/{}] time: {:.3f}s, g_loss(mse:{:.3f}, vgg:{:.3f}, adv:{:.3f}) d_loss: {:.3f}\".format(\n","                epoch, n_epoch_init, step, n_step_epoch, time.time() - step_time, mse_loss, vgg_loss, g_gan_loss, d_loss))\n","\n","        # update the learning rate\n","        if epoch != 0 and (epoch % decay_every == 0):\n","            new_lr_decay = lr_decay**(epoch // decay_every)\n","            lr_v.assign(lr_init * new_lr_decay)\n","            log = \" ** new learning rate: %f (for GAN)\" % (lr_init * new_lr_decay)\n","            G.save_weights(os.path.join(checkpoint_dir, 'g.h5'))\n","            D.save_weights(os.path.join(checkpoint_dir, 'd.h5'))\n","            print(log)\n","\n","        if (epoch != 0) and (epoch % 10 == 0):\n","            tl.vis.save_images(fake_patchs.numpy(), [2, 4], os.path.join(save_dir, 'train_g_{}.png'.format(epoch)))\n","            G.save_weights(os.path.join(checkpoint_dir, 'g.h5'))\n","            D.save_weights(os.path.join(checkpoint_dir, 'd.h5'))\n","\n","def evaluate():\n","    ###====================== PRE-LOAD DATA ===========================###\n","\n","    valid_hr_img_list = sorted(tl.files.load_file_list(path=config.VALID.hr_img_path, regx='.*.jpg', printable=False))\n","    valid_lr_img_list = sorted(tl.files.load_file_list(path=config.VALID.lr_img_path, regx='.*.jpg', printable=False))\n","\n","\n","    valid_lr_imgs = tl.vis.read_images(valid_lr_img_list, path=config.VALID.lr_img_path, n_threads=32)\n","\n","    valid_hr_imgs = tl.vis.read_images(valid_hr_img_list, path=config.VALID.hr_img_path, n_threads=32)\n","\n","\n","    ###========================== DEFINE MODEL ============================###\n","    imid = 2  #\n","    valid_lr_img = valid_lr_imgs[imid]\n","    valid_hr_img = valid_hr_imgs[imid]\n","    #valid_lr_img = get_imgs_fn('000078.jpg', '/content/drive/My Drive/Colab Notebooks/vpt/celeb_HR/')  # if you want to test your own image\n","    valid_lr_img = (valid_lr_img / 127.5) - 1  # rescale to ［－1, 1]\n","\n","\n","    G = get_G([1, None, None, 3])\n","    G.load_weights(os.path.join(checkpoint_dir, 'g.h5'))\n","    G.eval()\n","\n","    valid_lr_img = np.asarray(valid_lr_img, dtype=np.float32)\n","    valid_lr_img = valid_lr_img[np.newaxis,:,:,:]\n","    size = [valid_lr_img.shape[1], valid_lr_img.shape[2]]\n","\n","    out = G(valid_lr_img).numpy()\n","    print(out.shape)\n","    #out = G(valid_lr_img)\n","    print(\"LR size: %s /  generated HR size: %s\" % (size, out.shape))  # LR size: (339, 510, 3) /  gen HR size: (1, 1356, 2040, 3)\n","    print(\"[*] save images\")\n","    tl.vis.save_image(out[0],os.path.join(save_dir, 'generated.jpg'))\n","    tl.vis.save_image(valid_lr_img[0], os.path.join(save_dir, 'Original.jpg'))\n","    tl.vis.save_image(valid_hr_img, os.path.join(save_dir, 'valid_hr.png'))\n","\n","    out_bicu = scipy.misc.imresize(valid_lr_img[0], [size[0] * 4, size[1] * 4], interp='bicubic', mode=None)\n","    tl.vis.save_image(out_bicu, os.path.join(save_dir, 'resized.jpg'))\n","\n","\n","if __name__ == '__main__':\n","\n","    train()\n","    #evaluate()\n","\n"],"execution_count":4,"outputs":[{"output_type":"stream","text":["[TL] [!] /content/drive/My Drive/Colab Notebooks/vpt/celeb_samples/samples exists ...\n","[TL] [!] /content/drive/My Drive/Colab Notebooks/vpt/celeb_samples/models exists ...\n","[TL] Input  _inputlayer_1: (2, 64, 64, 3)\n","[TL] Conv2d conv2d_1: n_filter: 64 filter_size: (3, 3) strides: (1, 1) pad: SAME act: relu\n","[TL] Conv2d conv2d_2: n_filter: 64 filter_size: (3, 3) strides: (1, 1) pad: SAME act: No Activation\n","[TL] BatchNorm batchnorm2d_1: decay: 0.900000 epsilon: 0.000010 act: relu is_train: False\n","[TL] Conv2d conv2d_3: n_filter: 64 filter_size: (3, 3) strides: (1, 1) pad: SAME act: No Activation\n","[TL] BatchNorm batchnorm2d_2: decay: 0.900000 epsilon: 0.000010 act: No Activation is_train: False\n","[TL] Elementwise elementwise_1: fn: add act: No Activation\n","[TL] Conv2d conv2d_4: n_filter: 64 filter_size: (3, 3) strides: (1, 1) pad: SAME act: No Activation\n","[TL] BatchNorm batchnorm2d_3: decay: 0.900000 epsilon: 0.000010 act: relu is_train: False\n","[TL] Conv2d conv2d_5: n_filter: 64 filter_size: (3, 3) strides: (1, 1) pad: SAME act: No Activation\n","[TL] BatchNorm batchnorm2d_4: decay: 0.900000 epsilon: 0.000010 act: No Activation is_train: False\n","[TL] Elementwise elementwise_2: fn: add act: No Activation\n","[TL] Conv2d conv2d_6: n_filter: 64 filter_size: (3, 3) strides: (1, 1) pad: SAME act: No Activation\n","[TL] BatchNorm batchnorm2d_5: decay: 0.900000 epsilon: 0.000010 act: relu is_train: False\n","[TL] Conv2d conv2d_7: n_filter: 64 filter_size: (3, 3) strides: (1, 1) pad: SAME act: No Activation\n","[TL] BatchNorm batchnorm2d_6: decay: 0.900000 epsilon: 0.000010 act: No Activation is_train: False\n","[TL] Elementwise elementwise_3: fn: add act: No Activation\n","[TL] Conv2d conv2d_8: n_filter: 64 filter_size: (3, 3) strides: (1, 1) pad: SAME act: No Activation\n","[TL] BatchNorm batchnorm2d_7: decay: 0.900000 epsilon: 0.000010 act: relu is_train: False\n","[TL] Conv2d conv2d_9: n_filter: 64 filter_size: (3, 3) strides: (1, 1) pad: SAME act: No Activation\n","[TL] BatchNorm batchnorm2d_8: decay: 0.900000 epsilon: 0.000010 act: No Activation is_train: False\n","[TL] Elementwise elementwise_4: fn: add act: No Activation\n","[TL] Conv2d conv2d_10: n_filter: 64 filter_size: (3, 3) strides: (1, 1) pad: SAME act: No Activation\n","[TL] BatchNorm batchnorm2d_9: decay: 0.900000 epsilon: 0.000010 act: relu is_train: False\n","[TL] Conv2d conv2d_11: n_filter: 64 filter_size: (3, 3) strides: (1, 1) pad: SAME act: No Activation\n","[TL] BatchNorm batchnorm2d_10: decay: 0.900000 epsilon: 0.000010 act: No Activation is_train: False\n","[TL] Elementwise elementwise_5: fn: add act: No Activation\n","[TL] Conv2d conv2d_12: n_filter: 64 filter_size: (3, 3) strides: (1, 1) pad: SAME act: No Activation\n","[TL] BatchNorm batchnorm2d_11: decay: 0.900000 epsilon: 0.000010 act: relu is_train: False\n","[TL] Conv2d conv2d_13: n_filter: 64 filter_size: (3, 3) strides: (1, 1) pad: SAME act: No Activation\n","[TL] BatchNorm batchnorm2d_12: decay: 0.900000 epsilon: 0.000010 act: No Activation is_train: False\n","[TL] Elementwise elementwise_6: fn: add act: No Activation\n","[TL] Conv2d conv2d_14: n_filter: 64 filter_size: (3, 3) strides: (1, 1) pad: SAME act: No Activation\n","[TL] BatchNorm batchnorm2d_13: decay: 0.900000 epsilon: 0.000010 act: relu is_train: False\n","[TL] Conv2d conv2d_15: n_filter: 64 filter_size: (3, 3) strides: (1, 1) pad: SAME act: No Activation\n","[TL] BatchNorm batchnorm2d_14: decay: 0.900000 epsilon: 0.000010 act: No Activation is_train: False\n","[TL] Elementwise elementwise_7: fn: add act: No Activation\n","[TL] Conv2d conv2d_16: n_filter: 64 filter_size: (3, 3) strides: (1, 1) pad: SAME act: No Activation\n","[TL] BatchNorm batchnorm2d_15: decay: 0.900000 epsilon: 0.000010 act: relu is_train: False\n","[TL] Conv2d conv2d_17: n_filter: 64 filter_size: (3, 3) strides: (1, 1) pad: SAME act: No Activation\n","[TL] BatchNorm batchnorm2d_16: decay: 0.900000 epsilon: 0.000010 act: No Activation is_train: False\n","[TL] Elementwise elementwise_8: fn: add act: No Activation\n","[TL] Conv2d conv2d_18: n_filter: 64 filter_size: (3, 3) strides: (1, 1) pad: SAME act: No Activation\n","[TL] BatchNorm batchnorm2d_17: decay: 0.900000 epsilon: 0.000010 act: relu is_train: False\n","[TL] Conv2d conv2d_19: n_filter: 64 filter_size: (3, 3) strides: (1, 1) pad: SAME act: No Activation\n","[TL] BatchNorm batchnorm2d_18: decay: 0.900000 epsilon: 0.000010 act: No Activation is_train: False\n","[TL] Elementwise elementwise_9: fn: add act: No Activation\n","[TL] Conv2d conv2d_20: n_filter: 64 filter_size: (3, 3) strides: (1, 1) pad: SAME act: No Activation\n","[TL] BatchNorm batchnorm2d_19: decay: 0.900000 epsilon: 0.000010 act: relu is_train: False\n","[TL] Conv2d conv2d_21: n_filter: 64 filter_size: (3, 3) strides: (1, 1) pad: SAME act: No Activation\n","[TL] BatchNorm batchnorm2d_20: decay: 0.900000 epsilon: 0.000010 act: No Activation is_train: False\n","[TL] Elementwise elementwise_10: fn: add act: No Activation\n","[TL] Conv2d conv2d_22: n_filter: 64 filter_size: (3, 3) strides: (1, 1) pad: SAME act: No Activation\n","[TL] BatchNorm batchnorm2d_21: decay: 0.900000 epsilon: 0.000010 act: relu is_train: False\n","[TL] Conv2d conv2d_23: n_filter: 64 filter_size: (3, 3) strides: (1, 1) pad: SAME act: No Activation\n","[TL] BatchNorm batchnorm2d_22: decay: 0.900000 epsilon: 0.000010 act: No Activation is_train: False\n","[TL] Elementwise elementwise_11: fn: add act: No Activation\n","[TL] Conv2d conv2d_24: n_filter: 64 filter_size: (3, 3) strides: (1, 1) pad: SAME act: No Activation\n","[TL] BatchNorm batchnorm2d_23: decay: 0.900000 epsilon: 0.000010 act: relu is_train: False\n","[TL] Conv2d conv2d_25: n_filter: 64 filter_size: (3, 3) strides: (1, 1) pad: SAME act: No Activation\n","[TL] BatchNorm batchnorm2d_24: decay: 0.900000 epsilon: 0.000010 act: No Activation is_train: False\n","[TL] Elementwise elementwise_12: fn: add act: No Activation\n","[TL] Conv2d conv2d_26: n_filter: 64 filter_size: (3, 3) strides: (1, 1) pad: SAME act: No Activation\n","[TL] BatchNorm batchnorm2d_25: decay: 0.900000 epsilon: 0.000010 act: relu is_train: False\n","[TL] Conv2d conv2d_27: n_filter: 64 filter_size: (3, 3) strides: (1, 1) pad: SAME act: No Activation\n","[TL] BatchNorm batchnorm2d_26: decay: 0.900000 epsilon: 0.000010 act: No Activation is_train: False\n","[TL] Elementwise elementwise_13: fn: add act: No Activation\n","[TL] Conv2d conv2d_28: n_filter: 64 filter_size: (3, 3) strides: (1, 1) pad: SAME act: No Activation\n","[TL] BatchNorm batchnorm2d_27: decay: 0.900000 epsilon: 0.000010 act: relu is_train: False\n","[TL] Conv2d conv2d_29: n_filter: 64 filter_size: (3, 3) strides: (1, 1) pad: SAME act: No Activation\n","[TL] BatchNorm batchnorm2d_28: decay: 0.900000 epsilon: 0.000010 act: No Activation is_train: False\n","[TL] Elementwise elementwise_14: fn: add act: No Activation\n","[TL] Conv2d conv2d_30: n_filter: 64 filter_size: (3, 3) strides: (1, 1) pad: SAME act: No Activation\n","[TL] BatchNorm batchnorm2d_29: decay: 0.900000 epsilon: 0.000010 act: relu is_train: False\n","[TL] Conv2d conv2d_31: n_filter: 64 filter_size: (3, 3) strides: (1, 1) pad: SAME act: No Activation\n","[TL] BatchNorm batchnorm2d_30: decay: 0.900000 epsilon: 0.000010 act: No Activation is_train: False\n","[TL] Elementwise elementwise_15: fn: add act: No Activation\n","[TL] Conv2d conv2d_32: n_filter: 64 filter_size: (3, 3) strides: (1, 1) pad: SAME act: No Activation\n","[TL] BatchNorm batchnorm2d_31: decay: 0.900000 epsilon: 0.000010 act: relu is_train: False\n","[TL] Conv2d conv2d_33: n_filter: 64 filter_size: (3, 3) strides: (1, 1) pad: SAME act: No Activation\n","[TL] BatchNorm batchnorm2d_32: decay: 0.900000 epsilon: 0.000010 act: No Activation is_train: False\n","[TL] Elementwise elementwise_16: fn: add act: No Activation\n","[TL] Conv2d conv2d_34: n_filter: 64 filter_size: (3, 3) strides: (1, 1) pad: SAME act: No Activation\n","[TL] BatchNorm batchnorm2d_33: decay: 0.900000 epsilon: 0.000010 act: No Activation is_train: False\n","[TL] Elementwise elementwise_17: fn: add act: No Activation\n","[TL] Conv2d conv2d_35: n_filter: 256 filter_size: (3, 3) strides: (1, 1) pad: SAME act: No Activation\n","[TL] SubpixelConv2d  subpixelconv2d_1: scale: 2 act: relu\n","[TL] Conv2d conv2d_36: n_filter: 256 filter_size: (3, 3) strides: (1, 1) pad: SAME act: No Activation\n","[TL] SubpixelConv2d  subpixelconv2d_2: scale: 2 act: relu\n","[TL] Conv2d conv2d_37: n_filter: 3 filter_size: (1, 1) strides: (1, 1) pad: SAME act: tanh\n","(2, 256, 256, 3)\n","[TL] Input  _inputlayer_2: (2, 128, 128, 3)\n","[TL] Conv2d conv2d_38: n_filter: 64 filter_size: (4, 4) strides: (2, 2) pad: SAME act: <lambda>\n","[TL] Conv2d conv2d_39: n_filter: 128 filter_size: (4, 4) strides: (2, 2) pad: SAME act: No Activation\n","[TL] BatchNorm batchnorm2d_34: decay: 0.900000 epsilon: 0.000010 act: <lambda> is_train: False\n","[TL] Conv2d conv2d_40: n_filter: 256 filter_size: (4, 4) strides: (2, 2) pad: SAME act: No Activation\n","[TL] BatchNorm batchnorm2d_35: decay: 0.900000 epsilon: 0.000010 act: <lambda> is_train: False\n","[TL] Conv2d conv2d_41: n_filter: 512 filter_size: (4, 4) strides: (2, 2) pad: SAME act: No Activation\n","[TL] BatchNorm batchnorm2d_36: decay: 0.900000 epsilon: 0.000010 act: <lambda> is_train: False\n","[TL] Conv2d conv2d_42: n_filter: 1024 filter_size: (4, 4) strides: (2, 2) pad: SAME act: No Activation\n","[TL] BatchNorm batchnorm2d_37: decay: 0.900000 epsilon: 0.000010 act: <lambda> is_train: False\n","[TL] Conv2d conv2d_43: n_filter: 2048 filter_size: (4, 4) strides: (2, 2) pad: SAME act: No Activation\n","[TL] BatchNorm batchnorm2d_38: decay: 0.900000 epsilon: 0.000010 act: <lambda> is_train: False\n","[TL] Conv2d conv2d_44: n_filter: 1024 filter_size: (1, 1) strides: (1, 1) pad: SAME act: No Activation\n","[TL] BatchNorm batchnorm2d_39: decay: 0.900000 epsilon: 0.000010 act: <lambda> is_train: False\n","[TL] Conv2d conv2d_45: n_filter: 512 filter_size: (1, 1) strides: (1, 1) pad: SAME act: No Activation\n","[TL] BatchNorm batchnorm2d_40: decay: 0.900000 epsilon: 0.000010 act: No Activation is_train: False\n","[TL] Conv2d conv2d_46: n_filter: 128 filter_size: (1, 1) strides: (1, 1) pad: SAME act: No Activation\n","[TL] BatchNorm batchnorm2d_41: decay: 0.900000 epsilon: 0.000010 act: <lambda> is_train: False\n","[TL] Conv2d conv2d_47: n_filter: 128 filter_size: (3, 3) strides: (1, 1) pad: SAME act: No Activation\n","[TL] BatchNorm batchnorm2d_42: decay: 0.900000 epsilon: 0.000010 act: <lambda> is_train: False\n","[TL] Conv2d conv2d_48: n_filter: 512 filter_size: (3, 3) strides: (1, 1) pad: SAME act: No Activation\n","[TL] BatchNorm batchnorm2d_43: decay: 0.900000 epsilon: 0.000010 act: No Activation is_train: False\n","[TL] Elementwise elementwise_18: fn: add act: <lambda>\n","[TL] Flatten flatten_1:\n","[TL] Dense  dense_1: 1 No Activation\n","[TL] Input  _inputlayer_3: [None, 224, 224, 3]\n","[TL] Lambda  scale: func: <function VGG_static.<locals>.<lambda> at 0x7f29c7f07ea0>, len_weights: 0\n","[TL] Conv2d conv1_1: n_filter: 64 filter_size: (3, 3) strides: (1, 1) pad: SAME act: relu\n","[TL] Conv2d conv1_2: n_filter: 64 filter_size: (3, 3) strides: (1, 1) pad: SAME act: relu\n","[TL] MaxPool2d pool1: filter_size: (2, 2) strides: (2, 2) padding: SAME\n","[TL] Conv2d conv2_1: n_filter: 128 filter_size: (3, 3) strides: (1, 1) pad: SAME act: relu\n","[TL] Conv2d conv2_2: n_filter: 128 filter_size: (3, 3) strides: (1, 1) pad: SAME act: relu\n","[TL] MaxPool2d pool2: filter_size: (2, 2) strides: (2, 2) padding: SAME\n","[TL] Conv2d conv3_1: n_filter: 256 filter_size: (3, 3) strides: (1, 1) pad: SAME act: relu\n","[TL] Conv2d conv3_2: n_filter: 256 filter_size: (3, 3) strides: (1, 1) pad: SAME act: relu\n","[TL] Conv2d conv3_3: n_filter: 256 filter_size: (3, 3) strides: (1, 1) pad: SAME act: relu\n","[TL] Conv2d conv3_4: n_filter: 256 filter_size: (3, 3) strides: (1, 1) pad: SAME act: relu\n","[TL] MaxPool2d pool3: filter_size: (2, 2) strides: (2, 2) padding: SAME\n","[TL] Conv2d conv4_1: n_filter: 512 filter_size: (3, 3) strides: (1, 1) pad: SAME act: relu\n","[TL] Conv2d conv4_2: n_filter: 512 filter_size: (3, 3) strides: (1, 1) pad: SAME act: relu\n","[TL] Conv2d conv4_3: n_filter: 512 filter_size: (3, 3) strides: (1, 1) pad: SAME act: relu\n","[TL] Conv2d conv4_4: n_filter: 512 filter_size: (3, 3) strides: (1, 1) pad: SAME act: relu\n","[TL] MaxPool2d pool4: filter_size: (2, 2) strides: (2, 2) padding: SAME\n","[TL] LayerList layerlist_1 including layers [conv1_1, conv1_2, pool1, conv2_1, conv2_2, pool2, conv3_1, conv3_2, conv3_3, conv3_4, pool3, conv4_1, conv4_2, conv4_3, conv4_4, pool4]\n","[TL] Restore pre-trained weights\n","[TL] Downloading vgg19.npy...\n","\n"],"name":"stdout"},{"output_type":"stream","text":[" 92% (65023 of 70151) |################  | Elapsed Time: 0:01:26 ETA:   0:00:06"],"name":"stderr"},{"output_type":"stream","text":["[TL]   Loading (3, 3, 3, 64) in conv1_1\n","[TL]   Loading (64,) in conv1_1\n","[TL]   Loading (3, 3, 64, 64) in conv1_2\n","[TL]   Loading (64,) in conv1_2\n","[TL]   Loading (3, 3, 64, 128) in conv2_1\n","[TL]   Loading (128,) in conv2_1\n","[TL]   Loading (3, 3, 128, 128) in conv2_2\n","[TL]   Loading (128,) in conv2_2\n","[TL]   Loading (3, 3, 128, 256) in conv3_1\n","[TL]   Loading (256,) in conv3_1\n","[TL]   Loading (3, 3, 256, 256) in conv3_2\n","[TL]   Loading (256,) in conv3_2\n","[TL]   Loading (3, 3, 256, 256) in conv3_3\n","[TL]   Loading (256,) in conv3_3\n","[TL]   Loading (3, 3, 256, 256) in conv3_4\n","[TL]   Loading (256,) in conv3_4\n","[TL]   Loading (3, 3, 256, 512) in conv4_1\n","[TL]   Loading (512,) in conv4_1\n","[TL]   Loading (3, 3, 512, 512) in conv4_2\n","[TL]   Loading (512,) in conv4_2\n","[TL]   Loading (3, 3, 512, 512) in conv4_3\n","[TL]   Loading (512,) in conv4_3\n","[TL]   Loading (3, 3, 512, 512) in conv4_4\n","[TL]   Loading (512,) in conv4_4\n","[TL] read 32 from /content/drive/My Drive/Colab Notebooks/vpt/celeb_HR/\n","[TL] read 64 from /content/drive/My Drive/Colab Notebooks/vpt/celeb_HR/\n","[TL] read 96 from /content/drive/My Drive/Colab Notebooks/vpt/celeb_HR/\n","[TL] read 128 from /content/drive/My Drive/Colab Notebooks/vpt/celeb_HR/\n","[TL] read 160 from /content/drive/My Drive/Colab Notebooks/vpt/celeb_HR/\n","(2, 128, 128, 3)\n","(2, 128, 128, 3)\n","Epoch: [0/2] step: [0/1] time: 2.819s, mse: 0.363 \n","(2, 128, 128, 3)\n","(2, 128, 128, 3)\n","Epoch: [0/2] step: [1/1] time: 1.901s, mse: 0.358 \n","(2, 128, 128, 3)\n","(2, 128, 128, 3)\n","Epoch: [0/2] step: [2/1] time: 2.183s, mse: 0.229 \n","(2, 128, 128, 3)\n","(2, 128, 128, 3)\n","Epoch: [0/2] step: [3/1] time: 1.835s, mse: 0.234 \n","(2, 128, 128, 3)\n","(2, 128, 128, 3)\n","Epoch: [0/2] step: [4/1] time: 1.947s, mse: 0.325 \n","(2, 128, 128, 3)\n","(2, 128, 128, 3)\n","Epoch: [0/2] step: [5/1] time: 1.737s, mse: 0.212 \n","(2, 128, 128, 3)\n","(2, 128, 128, 3)\n","Epoch: [0/2] step: [6/1] time: 2.125s, mse: 0.268 \n","(2, 128, 128, 3)\n","(2, 128, 128, 3)\n","Epoch: [0/2] step: [7/1] time: 2.054s, mse: 0.251 \n","(2, 128, 128, 3)\n","(2, 128, 128, 3)\n","Epoch: [0/2] step: [8/1] time: 1.804s, mse: 0.262 \n","(2, 128, 128, 3)\n","(2, 128, 128, 3)\n","Epoch: [0/2] step: [9/1] time: 2.204s, mse: 0.292 \n","(2, 128, 128, 3)\n","(2, 128, 128, 3)\n","Epoch: [0/2] step: [10/1] time: 1.851s, mse: 0.305 \n","(2, 128, 128, 3)\n","(2, 128, 128, 3)\n","Epoch: [0/2] step: [11/1] time: 2.226s, mse: 0.243 \n","(2, 128, 128, 3)\n","(2, 128, 128, 3)\n","Epoch: [0/2] step: [12/1] time: 2.289s, mse: 0.244 \n","(2, 128, 128, 3)\n","(2, 128, 128, 3)\n","Epoch: [0/2] step: [13/1] time: 2.083s, mse: 0.464 \n","(2, 128, 128, 3)\n","(2, 128, 128, 3)\n","Epoch: [0/2] step: [14/1] time: 1.995s, mse: 0.175 \n","(2, 128, 128, 3)\n","(2, 128, 128, 3)\n","Epoch: [0/2] step: [15/1] time: 2.409s, mse: 0.276 \n","(2, 128, 128, 3)\n","(2, 128, 128, 3)\n","Epoch: [0/2] step: [16/1] time: 1.502s, mse: 0.324 \n","(2, 128, 128, 3)\n","(2, 128, 128, 3)\n","Epoch: [0/2] step: [17/1] time: 1.048s, mse: 0.198 \n","(2, 128, 128, 3)\n","(2, 128, 128, 3)\n","Epoch: [0/2] step: [18/1] time: 1.150s, mse: 0.191 \n","(2, 128, 128, 3)\n","(2, 128, 128, 3)\n","Epoch: [0/2] step: [19/1] time: 1.109s, mse: 0.257 \n","(2, 128, 128, 3)\n","(2, 128, 128, 3)\n","Epoch: [0/2] step: [20/1] time: 1.200s, mse: 0.147 \n","(2, 128, 128, 3)\n","(2, 128, 128, 3)\n","Epoch: [0/2] step: [21/1] time: 1.244s, mse: 0.206 \n","(2, 128, 128, 3)\n","(2, 128, 128, 3)\n","Epoch: [0/2] step: [22/1] time: 1.087s, mse: 0.174 \n","(2, 128, 128, 3)\n","(2, 128, 128, 3)\n","Epoch: [0/2] step: [23/1] time: 1.093s, mse: 0.118 \n","(2, 128, 128, 3)\n","(2, 128, 128, 3)\n","Epoch: [0/2] step: [24/1] time: 1.076s, mse: 0.191 \n","(2, 128, 128, 3)\n","(2, 128, 128, 3)\n","Epoch: [0/2] step: [25/1] time: 1.123s, mse: 0.081 \n","(2, 128, 128, 3)\n","(2, 128, 128, 3)\n","Epoch: [0/2] step: [26/1] time: 1.403s, mse: 0.131 \n","(2, 128, 128, 3)\n","(2, 128, 128, 3)\n","Epoch: [0/2] step: [27/1] time: 1.194s, mse: 0.085 \n","(2, 128, 128, 3)\n","(2, 128, 128, 3)\n","Epoch: [0/2] step: [28/1] time: 1.085s, mse: 0.121 \n","(2, 128, 128, 3)\n","(2, 128, 128, 3)\n","Epoch: [0/2] step: [29/1] time: 1.160s, mse: 0.118 \n","(2, 128, 128, 3)\n","(2, 128, 128, 3)\n","Epoch: [0/2] step: [30/1] time: 1.075s, mse: 0.190 \n","(2, 128, 128, 3)\n","(2, 128, 128, 3)\n","Epoch: [0/2] step: [31/1] time: 1.302s, mse: 0.087 \n","(2, 128, 128, 3)\n","(2, 128, 128, 3)\n","Epoch: [0/2] step: [32/1] time: 1.248s, mse: 0.141 \n","(2, 128, 128, 3)\n","(2, 128, 128, 3)\n","Epoch: [0/2] step: [33/1] time: 1.188s, mse: 0.052 \n","(2, 128, 128, 3)\n","(2, 128, 128, 3)\n","Epoch: [0/2] step: [34/1] time: 1.191s, mse: 0.064 \n","(2, 128, 128, 3)\n","(2, 128, 128, 3)\n","Epoch: [0/2] step: [35/1] time: 1.102s, mse: 0.074 \n","(2, 128, 128, 3)\n","(2, 128, 128, 3)\n","Epoch: [0/2] step: [36/1] time: 1.053s, mse: 0.073 \n","(2, 128, 128, 3)\n","(2, 128, 128, 3)\n","Epoch: [0/2] step: [37/1] time: 1.133s, mse: 0.073 \n","(2, 128, 128, 3)\n","(2, 128, 128, 3)\n","Epoch: [0/2] step: [38/1] time: 1.373s, mse: 0.138 \n","(2, 128, 128, 3)\n","(2, 128, 128, 3)\n","Epoch: [0/2] step: [39/1] time: 1.217s, mse: 0.081 \n","(2, 128, 128, 3)\n","(2, 128, 128, 3)\n","Epoch: [0/2] step: [40/1] time: 1.182s, mse: 0.042 \n","(2, 128, 128, 3)\n","(2, 128, 128, 3)\n","Epoch: [0/2] step: [41/1] time: 1.136s, mse: 0.081 \n","(2, 128, 128, 3)\n","(2, 128, 128, 3)\n","Epoch: [0/2] step: [42/1] time: 1.188s, mse: 0.115 \n","(2, 128, 128, 3)\n","(2, 128, 128, 3)\n","Epoch: [0/2] step: [43/1] time: 1.183s, mse: 0.065 \n","(2, 128, 128, 3)\n","(2, 128, 128, 3)\n","Epoch: [0/2] step: [44/1] time: 1.263s, mse: 0.086 \n","(2, 128, 128, 3)\n","(2, 128, 128, 3)\n","Epoch: [0/2] step: [45/1] time: 1.077s, mse: 0.117 \n","(2, 128, 128, 3)\n","(2, 128, 128, 3)\n","Epoch: [0/2] step: [46/1] time: 1.159s, mse: 0.165 \n","(2, 128, 128, 3)\n","(2, 128, 128, 3)\n","Epoch: [0/2] step: [47/1] time: 1.112s, mse: 0.089 \n","(2, 128, 128, 3)\n","(2, 128, 128, 3)\n","Epoch: [0/2] step: [48/1] time: 1.181s, mse: 0.090 \n","(2, 128, 128, 3)\n","(2, 128, 128, 3)\n","Epoch: [0/2] step: [49/1] time: 1.113s, mse: 0.081 \n","(2, 128, 128, 3)\n","(2, 128, 128, 3)\n","Epoch: [0/2] step: [50/1] time: 1.299s, mse: 0.061 \n","(2, 128, 128, 3)\n","(2, 128, 128, 3)\n","Epoch: [0/2] step: [51/1] time: 1.071s, mse: 0.115 \n","(2, 128, 128, 3)\n","(2, 128, 128, 3)\n","Epoch: [0/2] step: [52/1] time: 1.196s, mse: 0.083 \n","(2, 128, 128, 3)\n","(2, 128, 128, 3)\n","Epoch: [0/2] step: [53/1] time: 1.155s, mse: 0.084 \n","(2, 128, 128, 3)\n","(2, 128, 128, 3)\n","Epoch: [0/2] step: [54/1] time: 1.202s, mse: 0.063 \n","(2, 128, 128, 3)\n","(2, 128, 128, 3)\n","Epoch: [0/2] step: [55/1] time: 1.356s, mse: 0.060 \n","(2, 128, 128, 3)\n","(2, 128, 128, 3)\n","Epoch: [0/2] step: [56/1] time: 1.186s, mse: 0.090 \n","(2, 128, 128, 3)\n","(2, 128, 128, 3)\n","Epoch: [0/2] step: [57/1] time: 1.102s, mse: 0.083 \n","(2, 128, 128, 3)\n","(2, 128, 128, 3)\n","Epoch: [0/2] step: [58/1] time: 1.187s, mse: 0.067 \n","(2, 128, 128, 3)\n","(2, 128, 128, 3)\n","Epoch: [0/2] step: [59/1] time: 1.106s, mse: 0.056 \n","(2, 128, 128, 3)\n","(2, 128, 128, 3)\n","Epoch: [0/2] step: [60/1] time: 1.253s, mse: 0.067 \n","(2, 128, 128, 3)\n","(2, 128, 128, 3)\n","Epoch: [0/2] step: [61/1] time: 1.141s, mse: 0.069 \n","(2, 128, 128, 3)\n","(2, 128, 128, 3)\n","Epoch: [0/2] step: [62/1] time: 1.082s, mse: 0.071 \n","(2, 128, 128, 3)\n","(2, 128, 128, 3)\n","Epoch: [0/2] step: [63/1] time: 1.092s, mse: 0.058 \n","(2, 128, 128, 3)\n","(2, 128, 128, 3)\n","Epoch: [0/2] step: [64/1] time: 1.172s, mse: 0.051 \n","(2, 128, 128, 3)\n","(2, 128, 128, 3)\n","Epoch: [0/2] step: [65/1] time: 1.098s, mse: 0.063 \n","(2, 128, 128, 3)\n","(2, 128, 128, 3)\n","Epoch: [0/2] step: [66/1] time: 1.193s, mse: 0.078 \n","(2, 128, 128, 3)\n","(2, 128, 128, 3)\n","Epoch: [0/2] step: [67/1] time: 1.246s, mse: 0.060 \n","(2, 128, 128, 3)\n","(2, 128, 128, 3)\n","Epoch: [0/2] step: [68/1] time: 1.222s, mse: 0.051 \n","(2, 128, 128, 3)\n","(2, 128, 128, 3)\n","Epoch: [0/2] step: [69/1] time: 1.156s, mse: 0.035 \n","(2, 128, 128, 3)\n","(2, 128, 128, 3)\n","Epoch: [0/2] step: [70/1] time: 1.128s, mse: 0.112 \n","(2, 128, 128, 3)\n","(2, 128, 128, 3)\n","Epoch: [0/2] step: [71/1] time: 1.135s, mse: 0.078 \n","(2, 128, 128, 3)\n","(2, 128, 128, 3)\n","Epoch: [0/2] step: [72/1] time: 1.111s, mse: 0.069 \n","(2, 128, 128, 3)\n","(2, 128, 128, 3)\n","Epoch: [0/2] step: [73/1] time: 1.365s, mse: 0.072 \n","(2, 128, 128, 3)\n","(2, 128, 128, 3)\n","Epoch: [0/2] step: [74/1] time: 1.132s, mse: 0.043 \n","(2, 128, 128, 3)\n","(2, 128, 128, 3)\n","Epoch: [0/2] step: [75/1] time: 1.078s, mse: 0.053 \n","(2, 128, 128, 3)\n","(2, 128, 128, 3)\n","Epoch: [0/2] step: [76/1] time: 1.127s, mse: 0.073 \n","(2, 128, 128, 3)\n","(2, 128, 128, 3)\n","Epoch: [0/2] step: [77/1] time: 1.185s, mse: 0.065 \n","(2, 128, 128, 3)\n","(2, 128, 128, 3)\n","Epoch: [0/2] step: [78/1] time: 1.233s, mse: 0.046 \n","(2, 128, 128, 3)\n","(2, 128, 128, 3)\n","Epoch: [0/2] step: [79/1] time: 1.397s, mse: 0.053 \n","(2, 128, 128, 3)\n","(2, 128, 128, 3)\n","Epoch: [1/2] step: [0/1] time: 1.169s, mse: 0.036 \n","(2, 128, 128, 3)\n","(2, 128, 128, 3)\n","Epoch: [1/2] step: [1/1] time: 1.073s, mse: 0.056 \n","(2, 128, 128, 3)\n","(2, 128, 128, 3)\n","Epoch: [1/2] step: [2/1] time: 1.108s, mse: 0.060 \n","(2, 128, 128, 3)\n","(2, 128, 128, 3)\n","Epoch: [1/2] step: [3/1] time: 1.112s, mse: 0.040 \n","(2, 128, 128, 3)\n","(2, 128, 128, 3)\n","Epoch: [1/2] step: [4/1] time: 1.224s, mse: 0.040 \n","(2, 128, 128, 3)\n","(2, 128, 128, 3)\n","Epoch: [1/2] step: [5/1] time: 1.109s, mse: 0.038 \n","(2, 128, 128, 3)\n","(2, 128, 128, 3)\n","Epoch: [1/2] step: [6/1] time: 1.076s, mse: 0.042 \n","(2, 128, 128, 3)\n","(2, 128, 128, 3)\n","Epoch: [1/2] step: [7/1] time: 1.179s, mse: 0.096 \n","(2, 128, 128, 3)\n","(2, 128, 128, 3)\n","Epoch: [1/2] step: [8/1] time: 1.177s, mse: 0.039 \n","(2, 128, 128, 3)\n","(2, 128, 128, 3)\n","Epoch: [1/2] step: [9/1] time: 1.267s, mse: 0.035 \n","(2, 128, 128, 3)\n","(2, 128, 128, 3)\n","Epoch: [1/2] step: [10/1] time: 1.120s, mse: 0.096 \n","(2, 128, 128, 3)\n","(2, 128, 128, 3)\n","Epoch: [1/2] step: [11/1] time: 1.202s, mse: 0.037 \n","(2, 128, 128, 3)\n","(2, 128, 128, 3)\n","Epoch: [1/2] step: [12/1] time: 1.082s, mse: 0.036 \n","(2, 128, 128, 3)\n","(2, 128, 128, 3)\n","Epoch: [1/2] step: [13/1] time: 1.172s, mse: 0.074 \n","(2, 128, 128, 3)\n","(2, 128, 128, 3)\n","Epoch: [1/2] step: [14/1] time: 1.226s, mse: 0.161 \n","(2, 128, 128, 3)\n","(2, 128, 128, 3)\n","Epoch: [1/2] step: [15/1] time: 1.204s, mse: 0.072 \n","(2, 128, 128, 3)\n","(2, 128, 128, 3)\n","Epoch: [1/2] step: [16/1] time: 1.389s, mse: 0.122 \n","(2, 128, 128, 3)\n","(2, 128, 128, 3)\n","Epoch: [1/2] step: [17/1] time: 1.096s, mse: 0.045 \n","(2, 128, 128, 3)\n","(2, 128, 128, 3)\n","Epoch: [1/2] step: [18/1] time: 1.178s, mse: 0.065 \n","(2, 128, 128, 3)\n","(2, 128, 128, 3)\n","Epoch: [1/2] step: [19/1] time: 1.148s, mse: 0.113 \n","(2, 128, 128, 3)\n","(2, 128, 128, 3)\n","Epoch: [1/2] step: [20/1] time: 1.098s, mse: 0.058 \n","(2, 128, 128, 3)\n","(2, 128, 128, 3)\n","Epoch: [1/2] step: [21/1] time: 1.155s, mse: 0.057 \n","(2, 128, 128, 3)\n","(2, 128, 128, 3)\n","Epoch: [1/2] step: [22/1] time: 1.371s, mse: 0.044 \n","(2, 128, 128, 3)\n","(2, 128, 128, 3)\n","Epoch: [1/2] step: [23/1] time: 1.187s, mse: 0.050 \n","(2, 128, 128, 3)\n","(2, 128, 128, 3)\n","Epoch: [1/2] step: [24/1] time: 1.073s, mse: 0.034 \n","(2, 128, 128, 3)\n","(2, 128, 128, 3)\n","Epoch: [1/2] step: [25/1] time: 1.108s, mse: 0.042 \n","(2, 128, 128, 3)\n","(2, 128, 128, 3)\n","Epoch: [1/2] step: [26/1] time: 1.190s, mse: 0.035 \n","(2, 128, 128, 3)\n","(2, 128, 128, 3)\n","Epoch: [1/2] step: [27/1] time: 1.195s, mse: 0.090 \n","(2, 128, 128, 3)\n","(2, 128, 128, 3)\n","Epoch: [1/2] step: [28/1] time: 1.271s, mse: 0.057 \n","(2, 128, 128, 3)\n","(2, 128, 128, 3)\n","Epoch: [1/2] step: [29/1] time: 1.167s, mse: 0.044 \n","(2, 128, 128, 3)\n","(2, 128, 128, 3)\n","Epoch: [1/2] step: [30/1] time: 1.207s, mse: 0.036 \n","(2, 128, 128, 3)\n","(2, 128, 128, 3)\n","Epoch: [1/2] step: [31/1] time: 1.079s, mse: 0.029 \n","(2, 128, 128, 3)\n","(2, 128, 128, 3)\n","Epoch: [1/2] step: [32/1] time: 1.110s, mse: 0.085 \n","(2, 128, 128, 3)\n","(2, 128, 128, 3)\n","Epoch: [1/2] step: [33/1] time: 1.204s, mse: 0.088 \n","(2, 128, 128, 3)\n","(2, 128, 128, 3)\n","Epoch: [1/2] step: [34/1] time: 1.190s, mse: 0.034 \n","(2, 128, 128, 3)\n","(2, 128, 128, 3)\n","Epoch: [1/2] step: [35/1] time: 1.083s, mse: 0.073 \n","(2, 128, 128, 3)\n","(2, 128, 128, 3)\n","Epoch: [1/2] step: [36/1] time: 1.085s, mse: 0.034 \n","(2, 128, 128, 3)\n","(2, 128, 128, 3)\n","Epoch: [1/2] step: [37/1] time: 1.166s, mse: 0.061 \n","(2, 128, 128, 3)\n","(2, 128, 128, 3)\n","Epoch: [1/2] step: [38/1] time: 1.206s, mse: 0.077 \n","(2, 128, 128, 3)\n","(2, 128, 128, 3)\n","Epoch: [1/2] step: [39/1] time: 1.078s, mse: 0.028 \n","(2, 128, 128, 3)\n","(2, 128, 128, 3)\n","Epoch: [1/2] step: [40/1] time: 1.103s, mse: 0.030 \n","(2, 128, 128, 3)\n","(2, 128, 128, 3)\n","Epoch: [1/2] step: [41/1] time: 1.098s, mse: 0.044 \n","(2, 128, 128, 3)\n","(2, 128, 128, 3)\n","Epoch: [1/2] step: [42/1] time: 1.091s, mse: 0.039 \n","(2, 128, 128, 3)\n","(2, 128, 128, 3)\n","Epoch: [1/2] step: [43/1] time: 1.185s, mse: 0.082 \n","(2, 128, 128, 3)\n","(2, 128, 128, 3)\n","Epoch: [1/2] step: [44/1] time: 1.099s, mse: 0.061 \n","(2, 128, 128, 3)\n","(2, 128, 128, 3)\n","Epoch: [1/2] step: [45/1] time: 1.213s, mse: 0.054 \n","(2, 128, 128, 3)\n","(2, 128, 128, 3)\n","Epoch: [1/2] step: [46/1] time: 1.081s, mse: 0.051 \n","(2, 128, 128, 3)\n","(2, 128, 128, 3)\n","Epoch: [1/2] step: [47/1] time: 1.059s, mse: 0.043 \n","(2, 128, 128, 3)\n","(2, 128, 128, 3)\n","Epoch: [1/2] step: [48/1] time: 1.072s, mse: 0.032 \n","(2, 128, 128, 3)\n","(2, 128, 128, 3)\n","Epoch: [1/2] step: [49/1] time: 1.139s, mse: 0.046 \n","(2, 128, 128, 3)\n","(2, 128, 128, 3)\n","Epoch: [1/2] step: [50/1] time: 1.098s, mse: 0.037 \n","(2, 128, 128, 3)\n","(2, 128, 128, 3)\n","Epoch: [1/2] step: [51/1] time: 1.390s, mse: 0.055 \n","(2, 128, 128, 3)\n","(2, 128, 128, 3)\n","Epoch: [1/2] step: [52/1] time: 1.194s, mse: 0.043 \n","(2, 128, 128, 3)\n","(2, 128, 128, 3)\n","Epoch: [1/2] step: [53/1] time: 1.122s, mse: 0.031 \n","(2, 128, 128, 3)\n","(2, 128, 128, 3)\n","Epoch: [1/2] step: [54/1] time: 1.200s, mse: 0.036 \n","(2, 128, 128, 3)\n","(2, 128, 128, 3)\n","Epoch: [1/2] step: [55/1] time: 1.125s, mse: 0.072 \n","(2, 128, 128, 3)\n","(2, 128, 128, 3)\n","Epoch: [1/2] step: [56/1] time: 1.100s, mse: 0.039 \n","(2, 128, 128, 3)\n","(2, 128, 128, 3)\n","Epoch: [1/2] step: [57/1] time: 1.242s, mse: 0.041 \n","(2, 128, 128, 3)\n","(2, 128, 128, 3)\n","Epoch: [1/2] step: [58/1] time: 1.215s, mse: 0.028 \n","(2, 128, 128, 3)\n","(2, 128, 128, 3)\n","Epoch: [1/2] step: [59/1] time: 1.167s, mse: 0.032 \n","(2, 128, 128, 3)\n","(2, 128, 128, 3)\n","Epoch: [1/2] step: [60/1] time: 1.127s, mse: 0.033 \n","(2, 128, 128, 3)\n","(2, 128, 128, 3)\n","Epoch: [1/2] step: [61/1] time: 1.189s, mse: 0.099 \n","(2, 128, 128, 3)\n","(2, 128, 128, 3)\n","Epoch: [1/2] step: [62/1] time: 1.225s, mse: 0.039 \n","(2, 128, 128, 3)\n","(2, 128, 128, 3)\n","Epoch: [1/2] step: [63/1] time: 1.154s, mse: 0.027 \n","(2, 128, 128, 3)\n","(2, 128, 128, 3)\n","Epoch: [1/2] step: [64/1] time: 1.146s, mse: 0.046 \n","(2, 128, 128, 3)\n","(2, 128, 128, 3)\n","Epoch: [1/2] step: [65/1] time: 1.064s, mse: 0.029 \n","(2, 128, 128, 3)\n","(2, 128, 128, 3)\n","Epoch: [1/2] step: [66/1] time: 1.138s, mse: 0.048 \n","(2, 128, 128, 3)\n","(2, 128, 128, 3)\n","Epoch: [1/2] step: [67/1] time: 1.364s, mse: 0.098 \n","(2, 128, 128, 3)\n","(2, 128, 128, 3)\n","Epoch: [1/2] step: [68/1] time: 1.204s, mse: 0.039 \n","(2, 128, 128, 3)\n","(2, 128, 128, 3)\n","Epoch: [1/2] step: [69/1] time: 1.181s, mse: 0.041 \n","(2, 128, 128, 3)\n","(2, 128, 128, 3)\n","Epoch: [1/2] step: [70/1] time: 1.094s, mse: 0.066 \n","(2, 128, 128, 3)\n","(2, 128, 128, 3)\n","Epoch: [1/2] step: [71/1] time: 1.053s, mse: 0.057 \n","(2, 128, 128, 3)\n","(2, 128, 128, 3)\n","Epoch: [1/2] step: [72/1] time: 1.139s, mse: 0.032 \n","(2, 128, 128, 3)\n","(2, 128, 128, 3)\n","Epoch: [1/2] step: [73/1] time: 1.083s, mse: 0.062 \n","(2, 128, 128, 3)\n","(2, 128, 128, 3)\n","Epoch: [1/2] step: [74/1] time: 1.387s, mse: 0.065 \n","(2, 128, 128, 3)\n","(2, 128, 128, 3)\n","Epoch: [1/2] step: [75/1] time: 1.152s, mse: 0.022 \n","(2, 128, 128, 3)\n","(2, 128, 128, 3)\n","Epoch: [1/2] step: [76/1] time: 1.064s, mse: 0.024 \n","(2, 128, 128, 3)\n","(2, 128, 128, 3)\n","Epoch: [1/2] step: [77/1] time: 1.051s, mse: 0.036 \n","(2, 128, 128, 3)\n","(2, 128, 128, 3)\n","Epoch: [1/2] step: [78/1] time: 1.108s, mse: 0.028 \n","(2, 128, 128, 3)\n","(2, 128, 128, 3)\n","Epoch: [1/2] step: [79/1] time: 1.137s, mse: 0.069 \n","Epoch: [0/2] step: [0/1] time: 10.852s, g_loss(mse:0.046, vgg:0.267, adv:0.000) d_loss: 1.601\n","Epoch: [0/2] step: [1/1] time: 11.212s, g_loss(mse:0.052, vgg:0.315, adv:0.001) d_loss: 1.953\n","Epoch: [0/2] step: [2/1] time: 10.419s, g_loss(mse:0.067, vgg:0.152, adv:0.001) d_loss: 1.530\n","Epoch: [0/2] step: [3/1] time: 10.106s, g_loss(mse:0.043, vgg:0.211, adv:0.001) d_loss: 1.716\n","Epoch: [0/2] step: [4/1] time: 10.471s, g_loss(mse:0.063, vgg:0.174, adv:0.000) d_loss: 2.241\n","Epoch: [0/2] step: [5/1] time: 10.565s, g_loss(mse:0.028, vgg:0.212, adv:0.000) d_loss: 1.593\n","Epoch: [0/2] step: [6/1] time: 10.502s, g_loss(mse:0.030, vgg:0.185, adv:0.000) d_loss: 1.676\n","Epoch: [0/2] step: [7/1] time: 10.705s, g_loss(mse:0.022, vgg:0.147, adv:0.001) d_loss: 1.353\n","Epoch: [0/2] step: [8/1] time: 10.699s, g_loss(mse:0.057, vgg:0.164, adv:0.001) d_loss: 1.719\n","Epoch: [0/2] step: [9/1] time: 10.758s, g_loss(mse:0.051, vgg:0.232, adv:0.001) d_loss: 1.710\n","Epoch: [0/2] step: [10/1] time: 10.282s, g_loss(mse:0.034, vgg:0.127, adv:0.001) d_loss: 1.673\n","Epoch: [0/2] step: [11/1] time: 10.497s, g_loss(mse:0.021, vgg:0.155, adv:0.001) d_loss: 1.660\n","Epoch: [0/2] step: [12/1] time: 10.893s, g_loss(mse:0.038, vgg:0.196, adv:0.001) d_loss: 2.094\n","Epoch: [0/2] step: [13/1] time: 10.645s, g_loss(mse:0.042, vgg:0.165, adv:0.001) d_loss: 1.384\n","Epoch: [0/2] step: [14/1] time: 10.350s, g_loss(mse:0.056, vgg:0.192, adv:0.000) d_loss: 2.082\n","Epoch: [0/2] step: [15/1] time: 10.825s, g_loss(mse:0.109, vgg:0.282, adv:0.001) d_loss: 1.198\n","Epoch: [0/2] step: [16/1] time: 10.382s, g_loss(mse:0.035, vgg:0.215, adv:0.001) d_loss: 1.493\n","Epoch: [0/2] step: [17/1] time: 10.670s, g_loss(mse:0.032, vgg:0.202, adv:0.001) d_loss: 1.337\n","Epoch: [0/2] step: [18/1] time: 10.487s, g_loss(mse:0.024, vgg:0.149, adv:0.001) d_loss: 1.708\n","Epoch: [0/2] step: [19/1] time: 10.479s, g_loss(mse:0.037, vgg:0.147, adv:0.001) d_loss: 1.244\n","Epoch: [0/2] step: [20/1] time: 10.570s, g_loss(mse:0.023, vgg:0.117, adv:0.001) d_loss: 1.573\n","Epoch: [0/2] step: [21/1] time: 10.519s, g_loss(mse:0.034, vgg:0.198, adv:0.001) d_loss: 2.089\n","Epoch: [0/2] step: [22/1] time: 10.600s, g_loss(mse:0.028, vgg:0.180, adv:0.001) d_loss: 1.239\n","Epoch: [0/2] step: [23/1] time: 10.818s, g_loss(mse:0.024, vgg:0.161, adv:0.001) d_loss: 1.732\n","Epoch: [0/2] step: [24/1] time: 10.568s, g_loss(mse:0.057, vgg:0.204, adv:0.000) d_loss: 1.979\n","Epoch: [0/2] step: [25/1] time: 10.423s, g_loss(mse:0.049, vgg:0.236, adv:0.001) d_loss: 1.638\n","Epoch: [0/2] step: [26/1] time: 11.293s, g_loss(mse:0.036, vgg:0.208, adv:0.000) d_loss: 1.299\n","Epoch: [0/2] step: [27/1] time: 10.121s, g_loss(mse:0.041, vgg:0.223, adv:0.001) d_loss: 1.517\n","Epoch: [0/2] step: [28/1] time: 10.732s, g_loss(mse:0.039, vgg:0.183, adv:0.001) d_loss: 2.047\n","Epoch: [0/2] step: [29/1] time: 10.453s, g_loss(mse:0.052, vgg:0.220, adv:0.001) d_loss: 2.320\n","Epoch: [0/2] step: [30/1] time: 10.180s, g_loss(mse:0.059, vgg:0.169, adv:0.001) d_loss: 1.962\n","Epoch: [0/2] step: [31/1] time: 10.599s, g_loss(mse:0.039, vgg:0.222, adv:0.001) d_loss: 1.076\n","Epoch: [0/2] step: [32/1] time: 10.791s, g_loss(mse:0.038, vgg:0.163, adv:0.001) d_loss: 1.253\n","Epoch: [0/2] step: [33/1] time: 10.475s, g_loss(mse:0.032, vgg:0.167, adv:0.001) d_loss: 1.218\n","Epoch: [0/2] step: [34/1] time: 10.589s, g_loss(mse:0.041, vgg:0.174, adv:0.000) d_loss: 1.720\n","Epoch: [0/2] step: [35/1] time: 10.681s, g_loss(mse:0.043, vgg:0.173, adv:0.001) d_loss: 1.310\n","Epoch: [0/2] step: [36/1] time: 10.723s, g_loss(mse:0.041, vgg:0.187, adv:0.001) d_loss: 1.726\n","Epoch: [0/2] step: [37/1] time: 10.190s, g_loss(mse:0.055, vgg:0.294, adv:0.000) d_loss: 1.571\n","Epoch: [0/2] step: [38/1] time: 10.464s, g_loss(mse:0.047, vgg:0.276, adv:0.000) d_loss: 2.012\n","Epoch: [0/2] step: [39/1] time: 10.630s, g_loss(mse:0.038, vgg:0.126, adv:0.001) d_loss: 1.397\n","Epoch: [0/2] step: [40/1] time: 10.648s, g_loss(mse:0.045, vgg:0.150, adv:0.001) d_loss: 1.548\n","Epoch: [0/2] step: [41/1] time: 10.685s, g_loss(mse:0.030, vgg:0.139, adv:0.001) d_loss: 1.240\n","Epoch: [0/2] step: [42/1] time: 10.385s, g_loss(mse:0.038, vgg:0.231, adv:0.001) d_loss: 1.865\n","Epoch: [0/2] step: [43/1] time: 10.608s, g_loss(mse:0.035, vgg:0.183, adv:0.002) d_loss: 1.770\n","Epoch: [0/2] step: [44/1] time: 10.456s, g_loss(mse:0.020, vgg:0.145, adv:0.001) d_loss: 1.483\n","Epoch: [0/2] step: [45/1] time: 10.417s, g_loss(mse:0.029, vgg:0.140, adv:0.001) d_loss: 1.374\n","Epoch: [0/2] step: [46/1] time: 10.433s, g_loss(mse:0.151, vgg:0.197, adv:0.002) d_loss: 1.936\n","Epoch: [0/2] step: [47/1] time: 10.595s, g_loss(mse:0.025, vgg:0.167, adv:0.001) d_loss: 1.887\n","Epoch: [0/2] step: [48/1] time: 10.626s, g_loss(mse:0.125, vgg:0.174, adv:0.000) d_loss: 1.470\n","Epoch: [0/2] step: [49/1] time: 10.215s, g_loss(mse:0.036, vgg:0.200, adv:0.001) d_loss: 1.330\n","Epoch: [0/2] step: [50/1] time: 10.289s, g_loss(mse:0.053, vgg:0.176, adv:0.001) d_loss: 1.438\n","Epoch: [0/2] step: [51/1] time: 10.003s, g_loss(mse:0.052, vgg:0.280, adv:0.001) d_loss: 1.465\n","Epoch: [0/2] step: [52/1] time: 10.396s, g_loss(mse:0.038, vgg:0.118, adv:0.001) d_loss: 1.497\n","Epoch: [0/2] step: [53/1] time: 10.064s, g_loss(mse:0.066, vgg:0.282, adv:0.001) d_loss: 1.382\n","Epoch: [0/2] step: [54/1] time: 10.478s, g_loss(mse:0.034, vgg:0.202, adv:0.001) d_loss: 1.280\n","Epoch: [0/2] step: [55/1] time: 10.588s, g_loss(mse:0.069, vgg:0.229, adv:0.001) d_loss: 1.498\n","Epoch: [0/2] step: [56/1] time: 11.057s, g_loss(mse:0.057, vgg:0.226, adv:0.001) d_loss: 1.905\n","Epoch: [0/2] step: [57/1] time: 10.270s, g_loss(mse:0.040, vgg:0.195, adv:0.001) d_loss: 1.525\n","Epoch: [0/2] step: [58/1] time: 10.210s, g_loss(mse:0.039, vgg:0.175, adv:0.001) d_loss: 1.184\n","Epoch: [0/2] step: [59/1] time: 10.916s, g_loss(mse:0.046, vgg:0.181, adv:0.001) d_loss: 1.293\n","Epoch: [0/2] step: [60/1] time: 10.411s, g_loss(mse:0.047, vgg:0.152, adv:0.000) d_loss: 1.744\n","Epoch: [0/2] step: [61/1] time: 10.216s, g_loss(mse:0.042, vgg:0.167, adv:0.001) d_loss: 1.934\n","Epoch: [0/2] step: [62/1] time: 10.466s, g_loss(mse:0.034, vgg:0.137, adv:0.001) d_loss: 1.698\n","Epoch: [0/2] step: [63/1] time: 10.653s, g_loss(mse:0.049, vgg:0.158, adv:0.001) d_loss: 1.407\n","Epoch: [0/2] step: [64/1] time: 10.926s, g_loss(mse:0.034, vgg:0.150, adv:0.001) d_loss: 1.291\n","Epoch: [0/2] step: [65/1] time: 10.232s, g_loss(mse:0.029, vgg:0.172, adv:0.000) d_loss: 1.597\n","Epoch: [0/2] step: [66/1] time: 10.134s, g_loss(mse:0.066, vgg:0.217, adv:0.001) d_loss: 1.981\n","Epoch: [0/2] step: [67/1] time: 10.984s, g_loss(mse:0.030, vgg:0.156, adv:0.001) d_loss: 1.522\n","Epoch: [0/2] step: [68/1] time: 10.263s, g_loss(mse:0.054, vgg:0.117, adv:0.002) d_loss: 1.468\n","Epoch: [0/2] step: [69/1] time: 10.262s, g_loss(mse:0.021, vgg:0.145, adv:0.001) d_loss: 1.770\n","Epoch: [0/2] step: [70/1] time: 10.428s, g_loss(mse:0.039, vgg:0.203, adv:0.001) d_loss: 1.521\n","Epoch: [0/2] step: [71/1] time: 10.572s, g_loss(mse:0.026, vgg:0.171, adv:0.001) d_loss: 1.445\n","Epoch: [0/2] step: [72/1] time: 10.764s, g_loss(mse:0.020, vgg:0.155, adv:0.001) d_loss: 1.535\n","Epoch: [0/2] step: [73/1] time: 10.232s, g_loss(mse:0.031, vgg:0.173, adv:0.001) d_loss: 1.583\n","Epoch: [0/2] step: [74/1] time: 10.646s, g_loss(mse:0.041, vgg:0.173, adv:0.001) d_loss: 1.447\n","Epoch: [0/2] step: [75/1] time: 10.462s, g_loss(mse:0.049, vgg:0.154, adv:0.001) d_loss: 1.334\n","Epoch: [0/2] step: [76/1] time: 10.400s, g_loss(mse:0.049, vgg:0.116, adv:0.001) d_loss: 1.187\n","Epoch: [0/2] step: [77/1] time: 10.653s, g_loss(mse:0.071, vgg:0.192, adv:0.002) d_loss: 2.005\n","Epoch: [0/2] step: [78/1] time: 10.525s, g_loss(mse:0.075, vgg:0.171, adv:0.001) d_loss: 1.897\n","Epoch: [0/2] step: [79/1] time: 10.451s, g_loss(mse:0.064, vgg:0.155, adv:0.001) d_loss: 2.302\n","Epoch: [1/2] step: [0/1] time: 10.820s, g_loss(mse:0.023, vgg:0.174, adv:0.001) d_loss: 1.422\n","Epoch: [1/2] step: [1/1] time: 10.568s, g_loss(mse:0.067, vgg:0.189, adv:0.001) d_loss: 1.292\n","Epoch: [1/2] step: [2/1] time: 10.290s, g_loss(mse:0.041, vgg:0.183, adv:0.001) d_loss: 1.502\n","Epoch: [1/2] step: [3/1] time: 10.158s, g_loss(mse:0.024, vgg:0.134, adv:0.001) d_loss: 1.373\n","Epoch: [1/2] step: [4/1] time: 10.941s, g_loss(mse:0.045, vgg:0.212, adv:0.001) d_loss: 1.681\n","Epoch: [1/2] step: [5/1] time: 10.554s, g_loss(mse:0.029, vgg:0.162, adv:0.001) d_loss: 2.162\n","Epoch: [1/2] step: [6/1] time: 11.111s, g_loss(mse:0.032, vgg:0.188, adv:0.001) d_loss: 1.812\n","Epoch: [1/2] step: [7/1] time: 10.620s, g_loss(mse:0.036, vgg:0.126, adv:0.001) d_loss: 1.522\n","Epoch: [1/2] step: [8/1] time: 10.370s, g_loss(mse:0.099, vgg:0.151, adv:0.000) d_loss: 1.572\n","Epoch: [1/2] step: [9/1] time: 10.419s, g_loss(mse:0.029, vgg:0.165, adv:0.001) d_loss: 1.658\n","Epoch: [1/2] step: [10/1] time: 10.218s, g_loss(mse:0.020, vgg:0.144, adv:0.000) d_loss: 1.272\n","Epoch: [1/2] step: [11/1] time: 11.260s, g_loss(mse:0.028, vgg:0.151, adv:0.001) d_loss: 1.601\n","Epoch: [1/2] step: [12/1] time: 10.523s, g_loss(mse:0.029, vgg:0.200, adv:0.000) d_loss: 1.758\n","Epoch: [1/2] step: [13/1] time: 10.242s, g_loss(mse:0.027, vgg:0.156, adv:0.001) d_loss: 1.413\n","Epoch: [1/2] step: [14/1] time: 10.644s, g_loss(mse:0.016, vgg:0.096, adv:0.001) d_loss: 1.898\n","Epoch: [1/2] step: [15/1] time: 10.364s, g_loss(mse:0.040, vgg:0.122, adv:0.001) d_loss: 2.069\n","Epoch: [1/2] step: [16/1] time: 10.633s, g_loss(mse:0.055, vgg:0.193, adv:0.001) d_loss: 2.244\n","Epoch: [1/2] step: [17/1] time: 10.559s, g_loss(mse:0.018, vgg:0.117, adv:0.002) d_loss: 1.974\n","Epoch: [1/2] step: [18/1] time: 10.358s, g_loss(mse:0.049, vgg:0.142, adv:0.001) d_loss: 1.761\n","Epoch: [1/2] step: [19/1] time: 10.586s, g_loss(mse:0.031, vgg:0.128, adv:0.002) d_loss: 1.737\n","Epoch: [1/2] step: [20/1] time: 10.348s, g_loss(mse:0.018, vgg:0.118, adv:0.001) d_loss: 1.799\n","Epoch: [1/2] step: [21/1] time: 10.403s, g_loss(mse:0.058, vgg:0.214, adv:0.001) d_loss: 1.488\n","Epoch: [1/2] step: [22/1] time: 10.804s, g_loss(mse:0.047, vgg:0.161, adv:0.001) d_loss: 1.694\n","Epoch: [1/2] step: [23/1] time: 10.629s, g_loss(mse:0.024, vgg:0.112, adv:0.000) d_loss: 1.832\n","Epoch: [1/2] step: [24/1] time: 10.663s, g_loss(mse:0.051, vgg:0.081, adv:0.000) d_loss: 1.642\n","Epoch: [1/2] step: [25/1] time: 10.404s, g_loss(mse:0.052, vgg:0.159, adv:0.001) d_loss: 1.413\n","Epoch: [1/2] step: [26/1] time: 10.708s, g_loss(mse:0.033, vgg:0.168, adv:0.000) d_loss: 1.697\n","Epoch: [1/2] step: [27/1] time: 10.622s, g_loss(mse:0.025, vgg:0.141, adv:0.001) d_loss: 1.679\n","Epoch: [1/2] step: [28/1] time: 11.357s, g_loss(mse:0.069, vgg:0.206, adv:0.001) d_loss: 1.440\n","Epoch: [1/2] step: [29/1] time: 10.772s, g_loss(mse:0.038, vgg:0.207, adv:0.000) d_loss: 1.560\n","Epoch: [1/2] step: [30/1] time: 10.282s, g_loss(mse:0.034, vgg:0.159, adv:0.001) d_loss: 1.441\n","Epoch: [1/2] step: [31/1] time: 10.504s, g_loss(mse:0.052, vgg:0.120, adv:0.000) d_loss: 1.733\n","Epoch: [1/2] step: [32/1] time: 10.831s, g_loss(mse:0.018, vgg:0.124, adv:0.000) d_loss: 1.564\n","Epoch: [1/2] step: [33/1] time: 10.178s, g_loss(mse:0.067, vgg:0.166, adv:0.001) d_loss: 1.755\n","Epoch: [1/2] step: [34/1] time: 10.343s, g_loss(mse:0.020, vgg:0.142, adv:0.001) d_loss: 1.463\n","Epoch: [1/2] step: [35/1] time: 11.180s, g_loss(mse:0.063, vgg:0.111, adv:0.001) d_loss: 1.546\n","Epoch: [1/2] step: [36/1] time: 10.214s, g_loss(mse:0.030, vgg:0.111, adv:0.001) d_loss: 1.671\n","Epoch: [1/2] step: [37/1] time: 10.608s, g_loss(mse:0.055, vgg:0.135, adv:0.001) d_loss: 1.372\n","Epoch: [1/2] step: [38/1] time: 10.289s, g_loss(mse:0.061, vgg:0.182, adv:0.001) d_loss: 1.522\n","Epoch: [1/2] step: [39/1] time: 10.260s, g_loss(mse:0.022, vgg:0.133, adv:0.001) d_loss: 1.434\n","Epoch: [1/2] step: [40/1] time: 11.248s, g_loss(mse:0.020, vgg:0.129, adv:0.001) d_loss: 1.256\n","Epoch: [1/2] step: [41/1] time: 10.891s, g_loss(mse:0.030, vgg:0.149, adv:0.002) d_loss: 2.270\n","Epoch: [1/2] step: [42/1] time: 10.182s, g_loss(mse:0.021, vgg:0.170, adv:0.001) d_loss: 1.400\n","Epoch: [1/2] step: [43/1] time: 10.236s, g_loss(mse:0.072, vgg:0.237, adv:0.001) d_loss: 1.372\n","Epoch: [1/2] step: [44/1] time: 10.255s, g_loss(mse:0.030, vgg:0.130, adv:0.001) d_loss: 1.374\n","Epoch: [1/2] step: [45/1] time: 10.626s, g_loss(mse:0.020, vgg:0.123, adv:0.001) d_loss: 1.432\n","Epoch: [1/2] step: [46/1] time: 10.405s, g_loss(mse:0.037, vgg:0.150, adv:0.001) d_loss: 1.468\n","Epoch: [1/2] step: [47/1] time: 10.270s, g_loss(mse:0.034, vgg:0.152, adv:0.001) d_loss: 1.550\n","Epoch: [1/2] step: [48/1] time: 10.616s, g_loss(mse:0.036, vgg:0.124, adv:0.000) d_loss: 1.485\n","Epoch: [1/2] step: [49/1] time: 10.436s, g_loss(mse:0.034, vgg:0.165, adv:0.001) d_loss: 1.383\n","Epoch: [1/2] step: [50/1] time: 10.238s, g_loss(mse:0.033, vgg:0.174, adv:0.001) d_loss: 1.488\n","Epoch: [1/2] step: [51/1] time: 10.376s, g_loss(mse:0.025, vgg:0.152, adv:0.000) d_loss: 1.582\n","Epoch: [1/2] step: [52/1] time: 10.500s, g_loss(mse:0.030, vgg:0.162, adv:0.001) d_loss: 1.495\n","Epoch: [1/2] step: [53/1] time: 10.725s, g_loss(mse:0.019, vgg:0.122, adv:0.001) d_loss: 1.628\n","Epoch: [1/2] step: [54/1] time: 10.518s, g_loss(mse:0.050, vgg:0.186, adv:0.001) d_loss: 1.612\n","Epoch: [1/2] step: [55/1] time: 10.680s, g_loss(mse:0.031, vgg:0.106, adv:0.001) d_loss: 1.561\n","Epoch: [1/2] step: [56/1] time: 10.251s, g_loss(mse:0.024, vgg:0.133, adv:0.001) d_loss: 1.625\n","Epoch: [1/2] step: [57/1] time: 11.581s, g_loss(mse:0.028, vgg:0.173, adv:0.001) d_loss: 1.400\n","Epoch: [1/2] step: [58/1] time: 10.758s, g_loss(mse:0.054, vgg:0.141, adv:0.001) d_loss: 1.470\n","Epoch: [1/2] step: [59/1] time: 10.472s, g_loss(mse:0.088, vgg:0.116, adv:0.001) d_loss: 1.300\n","Epoch: [1/2] step: [60/1] time: 10.304s, g_loss(mse:0.072, vgg:0.139, adv:0.001) d_loss: 1.336\n","Epoch: [1/2] step: [61/1] time: 10.031s, g_loss(mse:0.023, vgg:0.129, adv:0.001) d_loss: 1.556\n","Epoch: [1/2] step: [62/1] time: 9.964s, g_loss(mse:0.025, vgg:0.129, adv:0.000) d_loss: 1.623\n","Epoch: [1/2] step: [63/1] time: 10.701s, g_loss(mse:0.032, vgg:0.151, adv:0.000) d_loss: 1.534\n","Epoch: [1/2] step: [64/1] time: 10.354s, g_loss(mse:0.037, vgg:0.164, adv:0.000) d_loss: 1.453\n","Epoch: [1/2] step: [65/1] time: 10.911s, g_loss(mse:0.034, vgg:0.163, adv:0.001) d_loss: 1.392\n","Epoch: [1/2] step: [66/1] time: 10.424s, g_loss(mse:0.048, vgg:0.220, adv:0.001) d_loss: 1.469\n","Epoch: [1/2] step: [67/1] time: 9.786s, g_loss(mse:0.051, vgg:0.222, adv:0.001) d_loss: 1.428\n","Epoch: [1/2] step: [68/1] time: 10.057s, g_loss(mse:0.033, vgg:0.136, adv:0.001) d_loss: 1.423\n","Epoch: [1/2] step: [69/1] time: 10.399s, g_loss(mse:0.039, vgg:0.224, adv:0.002) d_loss: 1.632\n","Epoch: [1/2] step: [70/1] time: 11.516s, g_loss(mse:0.024, vgg:0.175, adv:0.000) d_loss: 1.408\n","Epoch: [1/2] step: [71/1] time: 10.656s, g_loss(mse:0.023, vgg:0.090, adv:0.001) d_loss: 1.253\n","Epoch: [1/2] step: [72/1] time: 11.384s, g_loss(mse:0.023, vgg:0.094, adv:0.001) d_loss: 1.800\n","Epoch: [1/2] step: [73/1] time: 10.611s, g_loss(mse:0.032, vgg:0.162, adv:0.001) d_loss: 1.382\n","Epoch: [1/2] step: [74/1] time: 10.743s, g_loss(mse:0.023, vgg:0.119, adv:0.001) d_loss: 1.492\n","Epoch: [1/2] step: [75/1] time: 10.317s, g_loss(mse:0.029, vgg:0.112, adv:0.001) d_loss: 1.429\n","Epoch: [1/2] step: [76/1] time: 10.364s, g_loss(mse:0.036, vgg:0.139, adv:0.000) d_loss: 1.544\n","Epoch: [1/2] step: [77/1] time: 10.316s, g_loss(mse:0.019, vgg:0.145, adv:0.000) d_loss: 1.528\n","Epoch: [1/2] step: [78/1] time: 10.461s, g_loss(mse:0.018, vgg:0.118, adv:0.000) d_loss: 1.749\n","Epoch: [1/2] step: [79/1] time: 10.576s, g_loss(mse:0.037, vgg:0.128, adv:0.001) d_loss: 1.401\n","[TL] [*] Saving TL weights into /content/drive/My Drive/Colab Notebooks/vpt/celeb_samples/models/g.h5\n","[TL] [*] Saved\n","[TL] [*] Saving TL weights into /content/drive/My Drive/Colab Notebooks/vpt/celeb_samples/models/d.h5\n","[TL] [*] Saved\n"," ** new learning rate: 0.000010 (for GAN)\n"],"name":"stdout"}]}]}